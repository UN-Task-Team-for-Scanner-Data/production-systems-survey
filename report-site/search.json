[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Interim Report: Survey of CPI Production Systems",
    "section": "",
    "text": "1 Introduction"
  },
  {
    "objectID": "index.html#value-suppression",
    "href": "index.html#value-suppression",
    "title": "Interim Report: Survey of CPI Production Systems",
    "section": "Value Suppression",
    "text": "Value Suppression\nTo preserve anonymity, we do not disclose any values if there are 2 or fewer respondents that take on the value. As a result, throughout the report, certain tables and figures may be presented in a way where certain categories are omitted or grouped together."
  },
  {
    "objectID": "intro.html#sec-motivation",
    "href": "intro.html#sec-motivation",
    "title": "1  Introduction",
    "section": "1.1 Motivation",
    "text": "1.1 Motivation\nIn our time working at NSOs, we have encountered some extremely complicated systems that exist in order to produce various analytical and data products such as consumer price indexes, national accounts figures, or labour force statistics. These complicated systems and the teams who maintain them are the subjects of this survey and write up. To reduce ambiguity, we refer to these systems as Complex Analytical Systems throughout this report.\nComplex Analytical Systems involve significant amounts of code, documentation, and other non-code artifacts such as Excel Workbooks that carry out complex business logic in order to transform input data into output data. Additionally, they are often developed entirely or in large part by people with backgrounds in Economics, Statistics, Mathematics, or another area related to the domain of Official Statistics.\nThese Complex Analytical Systems differ from traditional software systems in a number of important aspects4:\n\n\n\n\n\n\n\nComplex Analytical Systems\nTypical Software System\n\n\n\n\nMultiple distinct scripts that are run sequentially and perform complex data manipulations.\nOne code base representing an entire application.\n\n\nRunning time measured in minutes/hours\nRunning time measured in milliseconds.\n\n\nHuman in the loop activities to interpret results.\nCompletely autonomous system.\n\n\nAd-hoc (messy) data gathered from whatever data sources are available.\nHighly structured data whose schema is designed in lock step with the rest of the system.\n\n\nBatch workloads that are run manually (or semi-manually).\nSystem running continuously in an event loop waiting for user input.\n\n\nOperate on a large fraction of an entire table quickly.\nSearch for one specific record in a large table quickly.\n\n\n\nDue to differences like those mentioned above, there is not a perfect mapping between best practices from the software engineering world and pain points currently experienced by teams maintaining Complex Analytical Systems. However, there are certainly some best practices from software engineering that are highly appropriate to solve some of the problems faced in the development and maintenance of Complex Analytical Systems.\nTo this end, we hope our survey can help bridge the gap between well-understood industry best practices from the world of software engineering, and those aspects of Complex Analytical Systems that could benefit from these best practices. Our hope is that the insights gained and the survey methodology deployed may be valuable for other Complex Analytical Systems facing similar challenges."
  },
  {
    "objectID": "intro.html#sec-why-run-this-survey",
    "href": "intro.html#sec-why-run-this-survey",
    "title": "1  Introduction",
    "section": "1.2 What Was the Purpose of This Survey?",
    "text": "1.2 What Was the Purpose of This Survey?\nIn our experience, we’ve noticed that many teams who are responsible for Complex Analytical Systems struggle with managing many aspects of system complexity.\nComplex Analytical System business domain teams are typically comprised of individuals with strong analytical skills and significant domain knowledge, however, they often do not have specific training in software engineering concepts. Therefore, they are often not exposed to the significant body of knowledge that has been developed over decades to deal with the kinds of system complexity problems that software developers are routinely exposed to.\nWe have also found that individuals in these business domains are often missing the vocabulary and concepts to articulate the state of their Complex Analytical Systems. As a result, when these individuals try to explain where they are struggling to a more IT-oriented audience, miscommunication often results, and it becomes difficult to arrive at reasonable solutions.\nIn this survey, we ask questions that capture several germane aspects of system organization, team organization, technology choices, and business outcomes using language, terms, and conceptual models that are more familiar to individuals on these business domain teams. Our rationale for doing this is threefold.\n\nMeasure and describe the state of many Complex Analytical Systems around the world within a specific business domain (CPI Production Systems).\nProvide some concrete and practical suggestions to address common areas of struggle within this domain across many NSOs.\nExpose people from these business domain teams to software engineering concepts that are relevant in the development and maintenance of Complex Analytical Systems.\n\nWhile this report is tailored towards a Consumer Prices domain audience, we welcome and encourage readers from different domains to read through this report. We make significant efforts to avoid using too much domain-specific jargon, and present findings in a way that should comprehensible to a more general audience. In Chapter 10, we elaborate on aspects of our survey we believe to have high external validity, provide some practical suggestions that are applicable to Complex Analytical Systems in general, and describe some productive areas of future exploration that are not limited to the Consumer Prices business domain."
  },
  {
    "objectID": "intro.html#overview-of-cpi-production-systems",
    "href": "intro.html#overview-of-cpi-production-systems",
    "title": "1  Introduction",
    "section": "1.3 Overview of CPI Production Systems",
    "text": "1.3 Overview of CPI Production Systems\nWith the above motivation in mind, we conduct this survey for CPI Production Systems specifically, which are a kind of Complex Analytical System described in Section 1.1. More precisely, these systems take data on the price of consumer goods and services purchased throughout an economy and calculate period-over-period price changes of these goods and services. These price changes are ultimately mapped to a taxonomy of product categories, with the highest level of the taxonomy being the monthly “all items” CPI that is commonly used when discussing the overall level of inflation.\nThe recent adoption of alternative data sources in the calculation of CPIs has further increased the complexity of these systems,5 and has increased the importance of skills in newly emerging disciplines such as Data Science, Data Engineering, and Analytics Engineering."
  },
  {
    "objectID": "intro.html#related-work",
    "href": "intro.html#related-work",
    "title": "1  Introduction",
    "section": "1.4 Related Work",
    "text": "1.4 Related Work\nWe borrow and adapt several ideas presented in Skelton, Pais, and Malan (2019) such as the concepts of Stream-aligned teams and the Flow of change in our survey. These concepts (discussed in greater detail in the following sections) can be applied to understand how teams are organized around the various steps in a complex data processing workflow.\nWe also borrow a number of ideas from Forsgren, Humble, and Kim (2018). Particularly, multiple of the DevOps Research and Assessment (DORA) metrics they present are highly relevant in measuring the business outcomes of teams that maintain CPI systems6.\nWe believe that multiple ideas presented in Dehghani (2022) are highly applicable to the CPI Systems under study. Specifically, we believe that the concept of Data-as-a-Product (and teams organized around these Data Products) provides a useful framework for thinking about how these systems and teams interact with one another. We also contrast domain-oriented decentralized teams with centralized teams.\nAlthough we do not make specific references to it in our survey, we believe the Reproducible Analytical Pipeline (RAP) work by NHS (2017) does a good job at explaining how teams can introduce relevant tools and practices to workloads oriented around data processing.7\nThroughout this write up, we distinguish between software systems and IT professionals being embedded in domain teams versus being centralized outside of domain teams. Organizing software system architecture around business domains is not a new idea in software engineering (see Domain Driven Design by Evans (2004), and more recently Software Architecture: The Hard Parts by Ford et al. (2021) and Fundamentals of Software Architecture by Richards and Ford (2020), for example). However, we believe this distinction may not be well understood or formalized in the context of the teams who maintain the kinds of Complex Analytical Systems described in Section 1.2, so we pay special attention to this distinction throughout this write up."
  },
  {
    "objectID": "intro.html#how-this-report-is-organized",
    "href": "intro.html#how-this-report-is-organized",
    "title": "1  Introduction",
    "section": "1.6 How This Report Is Organized",
    "text": "1.6 How This Report Is Organized\nThis report is presented in the order that the survey was conducted, with findings presented along the way.\n\nChapter 2 covers the key conceptual models and terminology used to articulate concepts about system and team organization.\nChapter 3 analyzes our findings with respect to system and team organization.\nChapter 4 covers some high-level questions on the use of tools and technologies required to develop and maintain CPI Production Systems.\nChapter 5 covers questions about the age and update frequency of systems.\nChapter 6 covers questions about the number of individuals required to participate in system changes.\nChapter 7 covers questions about a concept called lead time, which measures the end-to-end time required to implement a change to a software component.\nChapter 8 covers questions about the usage of alternative data in CPI Production Systems.\nChapter 9 covers the challenges CPI Production System teams face with respect to maintaining their systems.\nChapter 10 concludes with a summary of the most notable findings from the survey, some practical insights to address some common areas of struggle, and some areas of future work."
  },
  {
    "objectID": "intro.html#note-on-confidentiality-and-privacy",
    "href": "intro.html#note-on-confidentiality-and-privacy",
    "title": "1  Introduction",
    "section": "1.7 Note on Confidentiality and Privacy",
    "text": "1.7 Note on Confidentiality and Privacy\nAs part of the administration of this survey, we ensured respondents that their data will be treated confidentiality. Therefore, no individual response data are made available in this report; all results presented are aggregated over all respondents.\n\n\n\n\nDehghani, Z. 2022. Data Mesh: Delivering Data-Driven Value at Scale. O’Reilly. https://books.google.ca/books?id=M5J5zgEACAAJ.\n\n\nEvans, E. 2004. Domain-Driven Design: Tackling Complexity in the Heart of Software. Addison-Wesley. https://books.google.ca/books?id=7dlaMs0SECsC.\n\n\nFord, N., W. M. Richards, P. J. Sadalage, and Z. Dehghani. 2021. Software Architecture: The Hard Parts : Modern Trade-Off Analysis for Distributed Architectures. O’Reilly. https://books.google.ca/books?id=sWNozgEACAAJ.\n\n\nForsgren, N., J. Humble, and G. Kim. 2018. Accelerate: The Science Behind DevOps : Building and Scaling High Performing Technology Organizations. G - Reference,information and Interdisciplinary Subjects Series. IT Revolution. https://books.google.ca/books?id=85XHAQAACAAJ.\n\n\nNHS. 2017. “Reproducible Analytical Pipelines (RAP).” https://nhsdigital.github.io/rap-community-of-practice/.\n\n\nPrice, M., and D. Marques. 2023. “Developing Reproducible Analytical Pipelines for the Transformation of Consumer Price Statistics: Rail Fares.” Office of National Statistics; \"https://unece.org/sites/default/files/2023-05/7.4%20UK_un_systems_railfares_paper.pdf\".\n\n\nRichards, M., and N. Ford. 2020. Fundamentals of Software Architecture: An Engineering Approach. O’Reilly Media, Incorporated. https://books.google.ca/books?id=_pNdwgEACAAJ.\n\n\nSkelton, M., M. Pais, and R. Malan. 2019. Team Topologies: Organizing Business and Technology Teams for Fast Flow. G - Reference,information and Interdisciplinary Subjects Series. IT Revolution. https://books.google.ca/books?id=oFdRuAEACAAJ."
  },
  {
    "objectID": "intro.html#footnotes",
    "href": "intro.html#footnotes",
    "title": "1  Introduction",
    "section": "",
    "text": "Most notable is the 2020 CPI Manual.↩︎\nSee the e-handbook, developed and maintained by the UN Task Team on Scanner data, for guidance on various aspects of leveraging new data sources.↩︎\nThe most notable approach being recommended is Reproducible Analytical Pipelines (or RAPs), which are discussed in Section 1.4. The IT system requirements section in the e-handbook also summarizes several considerations and approaches for systems development.↩︎\nWe are not implying that all “traditional” software systems have these characteristics. Rather, we are trying to draw contrast between aspects of Complex Analytical Systems that are most likely to be different from the kinds of systems a software engineer would often develop and maintain.↩︎\nIn the context of CPI Production Systems, alternative data sources refer to data such as retailer scanner and web-scraped data that can be used to calculate the component price changes that are used in CPI calculations.↩︎\nWe use slightly different terminology to refer to some of these concepts throughout the survey in order to use language that our target audience is most likely familiar with.↩︎\nFor readers who want to learn more about RAP, see this training session on RAP for price statistics by ESCAP which covers an application involving web scraping.↩︎"
  },
  {
    "objectID": "concepts.html#systems-and-teams",
    "href": "concepts.html#systems-and-teams",
    "title": "2  Concepts",
    "section": "2.1 Systems and Teams",
    "text": "2.1 Systems and Teams\n\n\n\n\n\n\nSystem Diagram\n\n\n\n\nFor the purposes of this survey, we define a system as any indivisible (atomic) software component that takes one or more data inputs and produces one or more data outputs.\n\n\n\nWhen we refer to an indivisible software component, we mean that the component runs “entirely or not at all” with respect to the transformation of inputs into outputs. For example, if there is one Python script that reads a file and writes an intermediate file, and a second R script that reads the intermediate file and produces another output file, we would consider this to be two separate systems.\nThe types of systems developed and maintained by the teams being surveyed can vary wildly. Therefore, we intentionally keep the definition of system vague so that it captures the key activity of transforming data without imposing any assumptions about how data are transformed.\nA team is defined as a group of individuals who maintain one or more systems. Teams can be composed of many different types of professionals, but for the purpose of this survey we distinguish between those who are Information Technology (IT) professionals (e.g., software developers) and those who are non-IT analysts (e.g., economists, statisticians).1\nImportantly, we also distinguish whether these teams are embedded in the price-statistics domain of the organization or work elsewhere in the organization. The detail we care about here is whether the team developing and maintaining one or more systems shares business context and domain knowledge with the team making use of these systems, or whether they do not share this business context and domain knowledge.\nIn total, we define the following 5 team types for the purposes of this survey.\n\n\n\n\n\n\n\nTeam Type\nDescription\n\n\n\n\nCorporate IT\nInformation Technology (IT) professionals who are part of an organization-wide central group (i.e., not functionally embedded in the price statistics team).\n\n\nDomain-Embedded IT\nIT professionals who are functionally embedded in the price statistics team (i.e., part of the price-statistics team, not the corporate IT department).\n\n\nDomain-Embedded Analysts\nProfessionals without a formal IT background (e.g., economists, statisticians) who are functionally embedded in the price statistics team.\n\n\nAnalysts Elsewhere in the Organization\nProfessionals without a formal IT background who are not functionally embedded in the price statistics team.\n\n\nExternal Consultants or Contractors\nProfessionals outside of the organization to whom system development/maintenance work is contracted."
  },
  {
    "objectID": "concepts.html#flow-of-change",
    "href": "concepts.html#flow-of-change",
    "title": "2  Concepts",
    "section": "2.2 Flow of Change",
    "text": "2.2 Flow of Change\nThe business processes that NSOs follow to create their country’s CPI is a special case of the General Statistical Business Process Model (GSBPM). We base our flow of change on the GSBPM model and specialize it slightly towards the CPI domain. We define each step in our flow of change as follows.\n\n\n\nFigure 2.1: Flow of Work\n\n\n\n\n\nProcess\nExplanation\n\n\n\n\nData Ingestion\nActivities to bring acquired data into a machine-readable state where it is ready for further processing. For example, entering paper surveys into an electronic database or querying a REST API to collect prices from a website.\n\n\nData Processing\nActivities to clean, validate, correct, impute, or otherwise adjust the data so that it is in a state where it is ready to be used to produce elementary indexes.\n\n\nElementary Indexes\nCalculate price indexes from the processed data for a given geography and product category (i.e., elementary aggregate) at a point in time.2\n\n\nAggregation\nAggregate the elementary price indexes into higher-level indexes (e.g., “All Items” CPI).3\n\n\nFinalization\nStore price indexes for subsequent use as part of analytical activities, and eventual dissemination.\n\n\n\nFigure 2.1 overlays all of the concepts discussed so far onto a single diagram. The flow of work (raw data to final CPI) can be read from left to right, with the green ovals representing systems and the boxes drawn around one or more systems representing the teams that own them.\nThe systems in these diagrams can be “piped” together, implying that the output of one system becomes the input to the next system. To simplify the notation, the intermediate input/output boxes are simply shown as an arrow from one system node to the next system node.\nIn the event that multiple teams collectively maintain a very large system, a team can be interpreted as the larger organizational unit that oversees the various sub-teams involved."
  },
  {
    "objectID": "concepts.html#putting-it-all-together",
    "href": "concepts.html#putting-it-all-together",
    "title": "2  Concepts",
    "section": "2.3 Putting it All Together",
    "text": "2.3 Putting it All Together\n\n\n\nFigure 2.2: Putting it All Together\n\n\nFigure 2.2 shows an example of what one of these diagrams could look like for a real NSO. A description of team/system organization that could correspond to this example is described below.\n\nA corporate IT team maintains a large Java application with an application-specific database that handles ingestion of most data sources.4\nA team of domain-embedded analysts (e.g., economists and statisticians) maintain a system written in Python, using pandas to ingest data from one source that does not integrate with the corporate system.5\nA team of domain-embedded analysts maintain a series of systems, using some combination of R and Python, that perform data processing and computation of elementary indexes.\n\nThe top system handles both the data processing step and the elementary index calculation step, implying it would not be straightforward to decouple these two concerns.\nThe bottom three cases have two distinct systems that handle data processing and elementary index calculation separately.\n\nA second system owned by corporate IT aggregates the elementary indexes and stores the resulting price indexes in a database."
  },
  {
    "objectID": "concepts.html#modular-vs.-monolithic-systems",
    "href": "concepts.html#modular-vs.-monolithic-systems",
    "title": "2  Concepts",
    "section": "2.4 Modular vs. Monolithic Systems",
    "text": "2.4 Modular vs. Monolithic Systems\nWe do not impose any restrictions on the number of systems that can belong under a team or a GSBPM step. Moreover, we do not impose any restriction on how many GSBPM steps a system can span. This flexibility lets us express the extent to which systems span across these GSBPM steps.\n\n\n\nFigure 2.3: Perfect Monolith Example\n\n\nFigure 2.3 and Figure 2.4 show contrasting examples of two extreme scenarios. Figure 2.3 is an example where there is one system owned by one team that handles all 5 GSBPM steps for all inputs. In contrast, Figure 2.4 shows the scenario where each GSBPM step has a dedicated system that does not cross between GSBPM steps.\n\n\n\nFigure 2.4: Perfect Modular Example\n\n\nIt is unlikely that any NSO will have systems organized like one of these extremes, rather most organizations will likely fall somewhere in between."
  },
  {
    "objectID": "concepts.html#representative-groups-of-systems",
    "href": "concepts.html#representative-groups-of-systems",
    "title": "2  Concepts",
    "section": "2.5 Representative Groups of Systems",
    "text": "2.5 Representative Groups of Systems\nTo get a complete understanding of each NSO’s team organization and system topology, we would need to have a comprehensive whiteboarding session with representatives from each NSO to fully articulate their CPI team structures and system architectures. This is obviously not feasible.\nTo get around this impracticality, we introduce the concept of a representative system group to the survey, which lets respondents describe one or more groups of systems that follow a typical pattern in their organization. Figure 2.5 shows what one such system group might look like using the example shown earlier in Figure 2.2.\n\n\n\nFigure 2.5: Representative System Group\n\n\nThe systems enclosed by the dashed red line in the diagram constitute a representative group, composed of three subgroups of systems.\n\nThere is a single system for data ingestion that is maintained by the organization’s corporate IT department (system group 1).\nThere are three systems that handle data processing and three systems that handle elementary index calculation. Each pair of systems is maintained by one or more small teams of domain-embedded analysts (system group 2).\nThere is one large system that handles aggregation and finalization of elementary index calculations. This system is also maintained by the corporate IT department (system group 3).\n\nOur rationale behind asking respondents to describe their representative system group is threefold:\n\nSignificantly reduce the response burden compared to completely articulating the state of all systems and teams that produce the CPI.\nReliably capture “system boundary” points where there is a switching between one group of systems and the next. While we do not have the resolution to know which GSBPM steps are crossed within a representative system group, we know for certain that there is a system boundary between two distinct representative system groups.\nReliably capture which kinds of teams occur together."
  },
  {
    "objectID": "concepts.html#footnotes",
    "href": "concepts.html#footnotes",
    "title": "2  Concepts",
    "section": "",
    "text": "We recognize there is some grey area as to whether or not certain occupations are considered to be IT, and that two organizations may classify the same positions differently.↩︎\nFor readers unfamiliar with the CPI domain, Elementary Aggregates (or EAs) are the most granular groups of goods and services for which expenditure shares are available. These EAs are the building blocks of the CPI. Calculated EAs are aggregated into higher-level indexes (weighted by expenditure shares), eventually rolling up to the “all items” CPI. For more detailed information, see sections 8.7 - 8.90 in Chapter 8 of the CPI Manual.↩︎\nThis step refers to the process of aggregating Elementary Aggregates to obtain higher-level price indexes, all the way to the “all items” CPI. Aggregation typically uses the CIOCOP classification structure. More information can be found in sections 8.91 - 8.96 in Chapter 8, in the CPI Manual.↩︎\nThe corporate IT team boxes are drawn in blue, indicating that they are a central-organization team that does not necessarily have detailed domain knowledge. In the absence of domain knowledge, this team would need to engage in a requirements gathering process with the domain team in order to build a system that performs the required capabilities.↩︎\nThe domain-embedded analyst boxes are drawn in yellow, indicating that they are a domain-aligned team.↩︎"
  },
  {
    "objectID": "systems-teams-analysis.html#steps-where-systems-are-coupled",
    "href": "systems-teams-analysis.html#steps-where-systems-are-coupled",
    "title": "3  Systems and Teams Analysis",
    "section": "3.1 Steps Where Systems are Coupled",
    "text": "3.1 Steps Where Systems are Coupled\nOne important piece of system architecture information we were interested in is cases where systems span more than one GSBPM step along the flow of change. Using our definition of “system” from Chapter 2, a system that spans two or more GSBPM steps implies that it would not be straightforward to modify just one GSBPM step in the system without affecting the others.1 This relates to the concept of coupling in software engineering, which measures the extent to which distinct software modules depend on each other.\n\n\n\nConceptual diagram of loose and high coupling. Source: https://en.wikipedia.org/wiki/Coupling_(computer_programming)\n\n\nWe asked the following question to get a coarse-grained understanding of systems that spanned more than one GSBPM step.\n\n\n\nSystems Spanning Multiple GSBPM Steps Question\n\n\nWe note how frequently systems cross certain GSBPM steps in Table 3.1.\n\n\nTable 3.1: Systems that span across multiple GSBPM steps\n\n\n\n\n\n\n\n\n\n\nData ingestion\nData processing\nElementary indexes\nAggregation\nFinalization\nFrequency\n\n\n\n\n✅\n✅\n❌\n❌\n❌\n21\n\n\n❌\n✅\n✅\n❌\n❌\n6\n\n\n❌\n❌\n✅\n✅\n❌\n0\n\n\n❌\n❌\n❌\n✅\n✅\n6\n\n\n✅\n✅\n✅\n❌\n❌\n12\n\n\n❌\n✅\n✅\n✅\n❌\n8\n\n\n❌\n❌\n✅\n✅\n✅\n11\n\n\n❌\n✅\n✅\n✅\n✅\n4\n\n\n✅\n✅\n✅\n✅\n✅\n20\n\n\n\n\nThe most common pattern we observed was that the same system handled both data ingestion and data processing with 21 occurrences. We suspect this is is fairly common as the two activities are conceptually similar, and often leverage similar tooling. For example, if an analyst wrote a web-scraping script to collect price data from a certain website, it’s reasonable that they would also perform some data cleaning activities in the same script before writing the output to persistent storage.\nThe second most common pattern we observed was the “Monolith” pattern, where we observe one system spanning all 5 GSBPM steps 20 times. We elaborate on this concept later in this section, but our suspicion is that systems like these mostly fall into one of two categories: (1) a small team and an Excel Workbook that handles everything from ingestion to finalization or (2) a single system managed by an IT team.\nMonolithic systems are not inherently bad. If they are carefully designed for maximum cohesion and minimal coupling, they can be maintainable. However, if monoliths emerge accidentally, they often involve many tightly coupled components and become very difficult to maintain in the long run.\nThe next two most frequent coupling patterns are ingestion-processing-elementary indexes (12 occurrences) and elementary indexes-aggregation-finalization (11 occurrences).\nA likely explanation for the former pattern is the existence of “mini-monolith” systems that perform all steps necessary to ingest, process, and create elementary aggregates using category-specific data and methods for a portion of the CPI. This form of system organization may create unnecessary coupling between these steps as changes to the data preparation activities may unduly impact elementary aggregation.2\nThe latter pattern may be likely to occur in NSOs that primarily leverage field collection and traditional methods. This form of system organization may create scaling challenges when alternative data sources and complex methods for these new data sources are introduced.\nSuprisingly, there were zero occurrences of a system spanning elementary indexes-aggregation. In fact, there were only 7 cases where finalization was handled as a standalone step, suggesting that finalization activities are often coupled with the previous steps."
  },
  {
    "objectID": "systems-teams-analysis.html#team-types-at-each-step",
    "href": "systems-teams-analysis.html#team-types-at-each-step",
    "title": "3  Systems and Teams Analysis",
    "section": "3.2 Team Types at Each Step",
    "text": "3.2 Team Types at Each Step\nThe next concept we try to learn in the survey is which types of teams discussed in Chapter 2 are present at each GSBPM step in the flow of change.\nWe present respondents with the following question.\n\n\n\nSystems Spanning Multiple GSBPM Steps Question\n\n\n\n\nTable 3.2: Common Team Combinations within GSBPM Steps\n\n\n\n\n\n\n\n\n\n\n\nData ingestion\nData processing\nElementary indexes\nAggregation\nFinalization\nFrequency\n\n\n\n\n\n❌\n❌\n✅\n❌\n❌\nDomain Analyst Only\n120\n\n\n❌\n✅\n✅\n❌\n❌\nDomain Analysts and Domain IT\n25\n\n\n✅\n❌\n❌\n❌\n❌\nCorporate IT-Only\n33\n\n\n❌\n✅\n❌\n❌\n❌\nDomain IT-Only\n20\n\n\n✅\n✅\n❌\n❌\n❌\nIT-Only\n11\n\n\n✅\n❌\n✅\n❌\n❌\nCorporate IT and Domain Analysts Only\n45\n\n\n\n\nTable 3.2 shows how frequently certain team combinations were reported within any given GSBPM step.\nWe were surprised to see that Corporate IT and Domain Analyst teams occurred almost twice as frequently as teams with Domain-embedded IT and Domain-embedded analysts. In particular, this suggests that technical expertise offered by IT personnel is often centralized outside of the domain area rather than functionally embedding IT personnel within the domain team."
  },
  {
    "objectID": "systems-teams-analysis.html#capturing-system-and-team-organizations-together",
    "href": "systems-teams-analysis.html#capturing-system-and-team-organizations-together",
    "title": "3  Systems and Teams Analysis",
    "section": "3.3 Capturing System And Team Organizations Together",
    "text": "3.3 Capturing System And Team Organizations Together"
  },
  {
    "objectID": "systems-teams-analysis.html#commonly-occurring-system-and-team-topologies",
    "href": "systems-teams-analysis.html#commonly-occurring-system-and-team-topologies",
    "title": "3  Systems and Teams Analysis",
    "section": "3.3 Commonly Occurring System and Team Topologies",
    "text": "3.3 Commonly Occurring System and Team Topologies\nWe begin by sharing some commonly occurring system and team topologies that occurred in our responses.\nWe perform k-means clustering with a cluster size of 3 on each respondent’s answer the “system topology” part of the Representative System Group question.3\nWe were not able to find any rule or explanation that perfectly split respondents into some number of clusters for this question.\nHowever, we were able to identify some high-level patterns that were consistent across the 3 groups. We use these patterns to characterize 3 archetypes that are explained below along with some illustrative examples from each cluster.\n\n3.3.1 One or more System Groups Span the Entire Flow of Change\n\n\n\n\n\n\nIngest\nProcess\nElementals\nAggregate\nFinalize\n\n\n\n\nSystem Group 1\nTRUE\nTRUE\nTRUE\nTRUE\nTRUE\n\n\nSystem Group 2\nFALSE\nFALSE\nFALSE\nFALSE\nFALSE\n\n\nSystem Group 3\nFALSE\nFALSE\nFALSE\nFALSE\nFALSE\n\n\nSystem Group 4\nFALSE\nFALSE\nFALSE\nFALSE\nFALSE\n\n\nSystem Group 5\nFALSE\nFALSE\nFALSE\nFALSE\nFALSE\n\n\n\n\n\n\n\n3.3.2 There is exactly one “split point” between System Groups\n\n\n\n\n\n\nIngest\nProcess\nElementals\nAggregate\nFinalize\n\n\n\n\nSystem Group 1\nTRUE\nTRUE\nFALSE\nFALSE\nFALSE\n\n\nSystem Group 2\nFALSE\nFALSE\nTRUE\nTRUE\nTRUE\n\n\nSystem Group 3\nFALSE\nFALSE\nFALSE\nFALSE\nFALSE\n\n\nSystem Group 4\nFALSE\nFALSE\nFALSE\nFALSE\nFALSE\n\n\nSystem Group 5\nFALSE\nFALSE\nFALSE\nFALSE\nFALSE\n\n\n\n\n\n\n\n3.3.3 There are two or more split points between system groups\n\n\n\n\n\n\nIngest\nProcess\nElementals\nAggregate\nFinalize\n\n\n\n\nSystem Group 1\nTRUE\nFALSE\nFALSE\nFALSE\nFALSE\n\n\nSystem Group 2\nFALSE\nTRUE\nFALSE\nFALSE\nFALSE\n\n\nSystem Group 3\nFALSE\nFALSE\nTRUE\nTRUE\nTRUE\n\n\nSystem Group 4\nFALSE\nFALSE\nFALSE\nFALSE\nFALSE\n\n\nSystem Group 5\nFALSE\nFALSE\nFALSE\nFALSE\nFALSE"
  },
  {
    "objectID": "systems-teams-analysis.html#assigning-architectures-to-organizations",
    "href": "systems-teams-analysis.html#assigning-architectures-to-organizations",
    "title": "3  Systems and Teams Analysis",
    "section": "3.4 Assigning Architectures to Organizations",
    "text": "3.4 Assigning Architectures to Organizations\nWe use responses to the Representative System Group question to assign NSOs to one of the three architecture types defined below.\n\n3.4.1 Monolithic Architecture\nWe assume that an NSO has a monolithic architecture if any of their system groups span all 5 GSBPM steps.4 We classify organizations where any system group spans all 5 GSBPM steps as monolithic because we are concerned with the precense of a system group that is plausibly monolithic, we do not have a large enough sample to distinguish between cases where there is a monolithic system group and another system group.\nOur reasoning for this assumption is that if the respondent thought a system group spanning all 5 GSBPM steps was similar enough that there was no need to split any subset of it into a second system group, it is probably due to coupling between one or more systems in the system group.\nIt is important to note that since we do not ask questions about the quantity or span of systems, we cannot know for certain whether or not a system group spanning all 5 GSBPM steps is truly monolithic.5\nFor example, a system group that spans all 5 GSBPM steps could be comprised of one system that truly is monolithic with respect to the 5 GSBPM steps, or it could be comprised of 5 or more distinct systems that the respondent felt were sufficiently representative of their typical workflow.6\nNevertheless, we needed to make some simplifying assumptions to make the response burden of this survey realistic, and we do not believe this assumption is too far fetched.\n\n\n3.4.2 Hybrid Architectures\nWe classify any NSO that (1) is not a monolith and (2) has exactly two system groups with any split between them as having a Hybrid architecture type.\nOur rationale for this category is to look at cases where there is one “boundary point” between two distinct system groups.\n\n\n3.4.3 Modular Architectures\nWe classify any NSO that (1) is not a monolith, (2) is not a hybrid, and (3) has three or more system groups with any splits between them as having a Modular architecture type.\nWhile this kind of architecture is not necessarily perfectly modular, there are definitely two or more “boundary points” between three or more distinct systems.\nThere are a couple of important points to note about Hybrid and Modular architectures as defined above.\n\nUnlike Monolithic architectures where we have to make an assumption about the internal structure of a system group, here we know for certain that there are explicit “boundary points” between two system groups that the respondent deemed sufficiently different to not be grouped together.\nUsing our definition of Systems given in Chapter 2, Hybrid and Modular architectures are guaranteed to pass output data from one system as input data to another system at least once7."
  },
  {
    "objectID": "systems-teams-analysis.html#assigning-team-types-to-organizations",
    "href": "systems-teams-analysis.html#assigning-team-types-to-organizations",
    "title": "3  Systems and Teams Analysis",
    "section": "3.5 Assigning Team Types to Organizations",
    "text": "3.5 Assigning Team Types to Organizations\nAs system architectures or development practices may be adopted differently by teams depending on their roles and technical skills, we categorize the initial team types we described in the survey into new team categories. Specifically:\n\nStream Aligned team: A system group is maintained by domain-analysts, domain-IT, or both. The idea is that these teams are comprised entirely of individuals who are embedded in the business domain.8 Therefore, they are likely to have a better understanding of the CPI business domain and thus may make different technical and organizational decisions than teams who lack this domain knowledge.\n\n\nIT-Only team: A system group is maintained by corporate-IT, domain-IT, or both. These teams are likely to have the necessary software engineering skills, but may or may not have the necessary domain knowledge.\nAnalyst-Only team: A system group is maintained by domain-analysts, elsewhere-analysts, or both. These teams are likely to have the necessary analysis and methodology skills, but may or may not have domain knowledge and also may not have the necessary software engineering skillset.\nOther Mix team: Assigned to organizations that have not been assigned to any of the above three team types.\n\n\n\n\n\n\n\nNote\n\n\n\nUnlike the architecture definitions earlier in this section, these team types are not mutually exclusive in the way we define them. For example, an organization could have one system group maintained by a Stream Aligned team, and a second system group maintained by an IT-Only team.9"
  },
  {
    "objectID": "systems-teams-analysis.html#are-certain-team-types-correlated-with-certain-architectures",
    "href": "systems-teams-analysis.html#are-certain-team-types-correlated-with-certain-architectures",
    "title": "3  Systems and Teams Analysis",
    "section": "3.6 Are Certain Team Types Correlated with Certain Architectures?",
    "text": "3.6 Are Certain Team Types Correlated with Certain Architectures?\nWe define similarity between organizations having a particular team type and a representative system with a particular architecture as follows.\n\\[\n\\text{Similarity} = \\frac{\\sum_{\\text{respondents}} \\text{Has Architecture Type} == 1 \\land \\text{Has Team Type} == 1}{\\sum_{\\text{respondents}} \\text{Has Team Type} == 1}\n\\]\nThe rationale for this similarity metric is that we care about what fraction of organizations with a particular team type also uses a given architecture type relative to how many instances of that team type are observed in the sample. Note that this can also be interpreted as a conditional probability where team type is the conditioning variable.\n\n\n\n\n\n\n\n\n\n\n\n\nMonolith\nHybrid\nModular\n\n\n\n\nStream Aligned Team\n0.465116279069767\n0.13953488372093\n0.395348837209302\n\n\nIT-Only Team\n0.346153846153846\n0.153846153846154\n0.5\n\n\nAnalyst-Only Team\n0.4\n0.2\n0.4\n\n\nOther Mix\n&gt; 0.75\n&lt; 0.25\n&lt; 0.25\n\n\nSample Average\n0.491803278688525\n0.147540983606557\n0.360655737704918\n\n\n\n\n\nThere are a few notable observations to point out in the above distribution.10\n\nIT-Only teams are more likely than average to be present in NSOs with Modular representative systems.\nStream-Aligned teams are more likely to be present in NSOs with Monolithic representative systems compared to IT-Only teams.\nOther Mix teams were much more likely to be present in NSOs with Monolithic representative systems compared to all other team types.11\n\nThroughout the remainder of this report, we look at how various practices and outcomes are associated with the presence of each architecture type and team type."
  },
  {
    "objectID": "systems-teams-analysis.html#footnotes",
    "href": "systems-teams-analysis.html#footnotes",
    "title": "3  Systems and Teams Analysis",
    "section": "",
    "text": "For example, a single Python script that processes data using Pandas and immediately performs a price index calculation on the processed data frame while it’s still in memory is a system that spans the (1) Processing and the (2) Elementary Indexes GSBPM steps. Such a system has coupled the Processing logic and the Elementary Indexes logic because it is not straightforward to change just the Processing component without also needing to consider how the Elementary Indexes component is affected.↩︎\nSee Goussev (2023) for an overview of the shift from data and method specific monolithic systems to a more standardized modular approach.↩︎\nDue to the small sample size, we were hesitant to try and split the sample into more than 3 groups. While there are almost certainly more than 3 meaningful system topologies that describe CPI Production Systems, our concern was that using more than 3 clusters would lead to us picking up idiosyncrasies in this specific sample rather than more general patterns that are likely true in a more general setting.↩︎\nThere were also two NSOs who explicitly stated that the same system does not handle more than one step for making their CPI across all systems. We assign these two records to the “modular” architecture category regardless of their answer to the Representative System Group question.↩︎\nIt is probably more realistic to think about the monolithic category as “more likely to have significant coupling between systems compared to organizations categorized as modular” rather than a true monolith in the strict sense of the term.↩︎\nThe number of respondents classified as monoliths who stated that the same system handles more than one step for making their CPI across all systems is 21/29 (8/29 skipped this question). This evidence alone is not sufficient to know one way or the other if these cases are truly monolithic, but we take it as evidence that the majority of assignments to “monolith” explicitly indicated that at least some systems cut across GSBPM boundaries.↩︎\nThis is in contrast to managing data entirely within a single system, which may be happening in the monolithic architectures.↩︎\nIf we had a larger sample size, we would have imposed the restriction that both domain analyst and domain IT teams must be present so that we could ensure domain expertise and software engineering skills exist together. Due to the small sample size, however, we had to include respondents with teams comprised of domain analyst and/or domain IT teams.↩︎\nThe rationale for this decision is that we could not think of a sensible way to break ties. For example, if one system group is maintained by a Stream Aligned team and another is maintained by an IT-Only team, is the NSO more appropriately labelled as a Stream Aligned team or as an IT-Only team? We take care while presenting results to make clear that some NSOs may be classified in more than one category if more than one team type is present in their representative system description.↩︎\nHere and throughout this report, we do not make any claims about the statistical significance of our results as we could not think of any straightforward or meaningful way to compute confidence intervals over the small sample of data we collected. Moreover, our goal with this report is more descriptive than prescriptive. We are aiming to describe the current state of CPI Production Systems and present notable differences that are worth investigating further, rather than claiming what should be done using the results of this survey alone.↩︎\nIt is important to note that a relatively small fraction of the sample contained Other Mix teams, so this result could be partly or entirely explained by a small number of outliers.↩︎"
  },
  {
    "objectID": "tools-and-technology.html#sec-vcs",
    "href": "tools-and-technology.html#sec-vcs",
    "title": "4  Tools and Technologies",
    "section": "4.1 Version Control System Usage",
    "text": "4.1 Version Control System Usage\nComplex Analytical Systems, such as the systems used in monthly CPI Production, often need to synchronize and integrate multiple versions of related code, data, and documentation. This is especially important for creating reproducible analytical pipelines (NHS (2017)), or enabling multiple individuals to work concurrently on the same project.\nVersion Control Systems (VCS) are tools that systematically manage changes in a codebase over time. At the time of writing, Git is by far the most popular software for this purpose, and platforms such as Github and GitLab have built extensive functionality around projects managed with Git.1\n\n\n\n\n\nFigure 4.1: VCS used by survey respondents\n\n\n\n\nFigure 4.1 shows the VCS used by respondent NSOs.\nSurprisingly, the most common response by far was that the respondent did not use version control software at all for their CPI Production Systems. In fact, almost two thirds of the sample claims to use no VCS whatsoever or file-naming conventions.2\nOur hypothesis here is that (1) some commonly used file formats (e.g., Excel Workbooks) don’t lend themselves easily to well-established version control tools like Git and (2) a lack of familiarity with VCS tools in general.\nAnother interesting observation is that slightly less than one third of the sample uses Git and/or GitHub/GitLab.3\nA very small fraction of the sample indicated using other version control software such as Mercurial, Subversion, or built-in versioning capabilities of another tool/platform.\nWe echo the recommendations of RAP and the Turing way to adopt VCS.4 It may greatly reduce the cognitive load for teams who are not currently using any VCS or are only using file-naming conventions to manage source code and documentation for Complex Analytical Systems.5"
  },
  {
    "objectID": "tools-and-technology.html#commercial-software",
    "href": "tools-and-technology.html#commercial-software",
    "title": "4  Tools and Technologies",
    "section": "4.2 Commercial Software",
    "text": "4.2 Commercial Software\nThe next question we asked was which commercial software (if any) is used in each respondent’s CPI Production systems.\n\n\n\n\n\nFigure 4.2: Commercial software used by survey respondents\n\n\n\n\nOver two thirds of the respondents listed that Microsoft Excel was used in their CPI Production Systems.\nMicrosoft Excel satisfies a number of use cases for basic tabular data analysis, however, it is not an ideal tool for expressing business logic in Complex Analytical Systems.6 Some of the key reasons for this include:\n\nExcel Workbooks are stored in a binary format rather than a plain text format, which doesn’t integrate well with Version Control Systems.\nThere isn’t a well-defined entrypoint to an Excel Workbook (i.e., you can’t “run” an Excel workbook the same way you can “run” python main.py).\nThe business logic encoded into an Excel Workbook is often difficult to read and interpret for any non-trivial Workbook, making Excel Workbooks difficult to maintain as a unit of software.\nExcel Workbooks encourage a high degree of coupling between business logic and data.7\n\nIn a distant second to Microsoft Excel, we find SAS is the next most commonly used commercial product in CPI Production Systems."
  },
  {
    "objectID": "tools-and-technology.html#project-management-software",
    "href": "tools-and-technology.html#project-management-software",
    "title": "4  Tools and Technologies",
    "section": "4.3 Project Management Software",
    "text": "4.3 Project Management Software\nWe asked respondents which project management software they use to manage work done on their CPI Production Systems.\nThe exact set of features provided by project management software differ depending on the specific software used, but in general, this kind of software is used to plan and coordinate tasks, manage timelines, and track progress on work items. Given the complexity of the CPI and the many factors that need to be coordinated and tracked for each change, project management software has a major productivity impact on users.\nWe believe that using some purpose-built project management software for any non-trivial project is generally a good idea because it encourages a structure to the way projects are managed and it offers a way to reduce cognitive burden for project team members.8\n\n\n\n\n\nThe most common project management software reported was a shared Excel Workbook, with a bit less than half of respondents stating that they used this as their team’s primary means of project management.\nShared Excel Workbooks may be sufficient for keeping track of small tasks, but for any endeavour that requires managing code, data, and documentation changes across multiple individuals, this approach will lack a number of key features to facilitate the project management process.\nThe second most cited answer was not using any project management software whatsoever, with almost one third of respondents indicating this answer.\nGiven the complexity of CPI Production Systems, we were surprised to see so many individuals not using any project management software. For all but the simplest of initiatives, we believe there is significant value in adopting at least the basic features of some purpose-built project management software.9\nFinally, just over twenty percent of the sample reported using either GitHub Projects, GitLab Milestones, or Jira as their primary software for project management."
  },
  {
    "objectID": "tools-and-technology.html#programming-languages",
    "href": "tools-and-technology.html#programming-languages",
    "title": "4  Tools and Technologies",
    "section": "4.4 Programming Languages",
    "text": "4.4 Programming Languages\nWe asked respondents which programming languages are used to develop their CPI Production Systems. We found several observations noteworthy.\n\n\n\n\n\nFirst, just under half of the respondents indicated that they use SQL in the development of their CPI Production Systems.\nWe suspect this answer reflects the fact that SQL still remains a very popular choice of language for expressing tabular data manipulations, as well as the fact that many organizations reported using some kind of database management system (DBMS) in their CPI Production Systems. Our suspicion is that SQL is most commonly used in the ingestion and processing steps in the flow of change.10\nSecond, we notice than more than ninety percent of the sample reported using at least one of Python, R, and SAS in their CPI Production Systems. Interestingly, less than one quarter of these users reported using Python and/or R but not SAS. In other words, it is quite common for SAS to be used in conjunction with Python and/or R rather than being used instead of Python and/or R. A number of NSOs are working on rewriting the SAS code of older systems in open source languages like R. Hence, they may still operate systems written in SAS alongside newer systems written in open source languages.11\nThird, there are some differences in programming languages used between NSOs with monolithic representative systems and NSOs with modular representative systems.\nThe most noteworthy observation is that Java, C#, C/C++, Visual Basic, and Visual Basic Applications (VBA) are somewhat commonly used by NSOs with monolithic representative systems (almost two thirds) and almost never used by NSOs with modular representative systems (less than one quarter).\nAdditionally, we notice that slightly over one third of NSOs with monolithic representative systems report using R or SAS, while almost two thirds of NSOs with modular representative systems report using R or SAS."
  },
  {
    "objectID": "tools-and-technology.html#data-storage-tools",
    "href": "tools-and-technology.html#data-storage-tools",
    "title": "4  Tools and Technologies",
    "section": "4.5 Data Storage Tools",
    "text": "4.5 Data Storage Tools\nWe conclude the Tools and Technology portion of the survey by asking which data storage tools are in use by respondents in their CPI Production Systems.\n\n\n\n\n\n\nChoice of Storage (Overall)\n\n\n\n\n\n\n\nChoice of Storage (Monolith)\n\n\n\n\n\n\n\n\n\nChoice of Storage (Hybrid)\n\n\n\n\n\n\n\nChoice of Storage (Modular)\n\n\n\n\n\nWe found that:\n\nA very small percentage of the respondents reported using analytics optimized file formats such as Apache Parquet in their CPI Production Systems. There is a small learning curve associated with using these file formats, but they offer many benefits such as columnar storage on disk, data types supported natively by the file format, and a significantly smaller storage footprint due to columnar data compression strategies.12\nThere is an approximately equal split between the usage of Database Management Systems (DBMS) and file system storage, which is true across both NSOs with modular representative systems and NSOs with monolithic representative systems.\nThe small number of respondents who reported using something in addition to DBMS or filesystem storage all belonged to NSOs with modular or hybrid representative systems.\n\n\n\n\n\nNHS. 2017. “Reproducible Analytical Pipelines (RAP).” https://nhsdigital.github.io/rap-community-of-practice/."
  },
  {
    "objectID": "tools-and-technology.html#footnotes",
    "href": "tools-and-technology.html#footnotes",
    "title": "4  Tools and Technologies",
    "section": "",
    "text": "It is worth mentioning that git-adjacent software such as Data Version Control and Git Large File Storage exists to extend the versioning capabilities of Git to files you wouldn’t typically commit to a Git repository. However, this is a more advanced topic that we did not investigate in this survey.↩︎\nWhat we mean by file naming conventions is encoding the author, version, and date information into the names of multiple files as the primary system of revision control. E.g., analysis_collin_v1.py, analysis_steve_v2.py, analysis_collin_v2_final_2025_03.py, analysis_steve_v2_final_FINAL_2025_04.py, and so on.↩︎\nWe were surprised to find a small number of respondents indicated that they use Git but not a developer platform built around Git such as GitHub, GitLab, or BitBucket. We suspect that these individuals may work in an air-gapped network or similar situation without internet access and use Git locally without also using a tool like GitLab/GitHub.↩︎\nWhile adopting any VCS is an improvement over file naming conventions (or not using a VCS at all), it should be noted that Git is by far the most commonly used VCS at the time of writing this report. We therefore recommend Git specifically due to the extensive tooling that is built around Git repositories specifically (e.g., GitHub, GitLab).↩︎\nWe believe that most people working on CPI Production Systems have the aptitude to learn Git. However, we acknowledge that the learning curve for Git is non-trivial. Our recommendation to readers who are interested is to learn the basics and immediately put this knowledge into practice in your day-to-day activities. Over time, versioning files with Git will become second nature.↩︎\nOur criticism here applies to all spreadsheet software, not just Microsoft Excel. Our point is that spreadsheet workbooks are not an ideal unit of software for expressing business logic in Complex Analytical Systems.↩︎\nIn other words, you can’t easily “reuse” a piece of business logic from someone else’s Excel Workbook in the way that you can reuse a piece of source code.↩︎\nNote that we are not advocating for any specific project management software product. Rather, we are encouraging the use of any purpose-built project management software to facilitate managing non-trivial projects.↩︎\nBy “basic features”, we’re referring to capabilities such as task tracking, milestone tracking, and the ability to see which tasks each colleague is working on at any given time.↩︎\nTo minimize response burden, we did not ask respondents to enumerate programming languages used by GSBPM step, so we cannot say for sure in which step(s) SQL is used.↩︎\nDue to the scale and complexity of the task, many NSOs are considering Large Language Models (LLMs) in conjunction with human review and testing to facilitate the conversion of SAS code into another target language such as R or Python. For example, see the use case of CSO Ireland in section 3.2 Large Language Models for Official Statistics: HLG-MOS 2023 White paper or GPT for SAS to R by INSEE (France).↩︎\nWhile there is a learning curve for some of the concepts involved, reading and writing to analytics-optimized file formats like Parquet is very easy due to the existence of many well-documented third party packages. For example, Python’s Pandas can read parquet files directly as long as an engine like pyarrow or fastparquet is also installed.↩︎"
  },
  {
    "objectID": "system-age-and-updates.html#system-age",
    "href": "system-age-and-updates.html#system-age",
    "title": "5  System Age and Updates",
    "section": "5.1 System Age",
    "text": "5.1 System Age\nRespondents are presented with the following question.\n\n\n\nAge of Systems Survey Question\n\n\nIn this question, we aim to understand for how long the majority of CPI Production Systems at NSOs have been in operation.\nIn the context of this question, a system could be long-lived because (1) it was built in an extensible fashion and has been easy to update and maintain over a long time period, (2) the requirements of the system have changed very little over a long time period, or (3) every component of the system has been replaced at some point without ever doing a full “system rewrite” (see Theseus’s Paradox).\nTherefore, without more information about the maintenance history of these systems, we cannot say whether older systems are “good” or “bad”. Nevertheless, it is interesting to understand how old the typical CPI Production System is.\nWe share some notable observations and explanations below.\n\n\n\n\n\n\nSystem Age Distribution (Entire Sample)\n\n\n\n\n\n\n\nSystem Age Distribution (Monolith)\n\n\n\n\n\n\n\n\n\nSystem Age Distribution (Modular)\n\n\n\n\n\nThe system age distribution for NSOs with modular representative systems is approximately uniform, while NSOs with monolithic representative systems are more likely to report that the majority of their systems are between 6-20 years old, and less likely to report that the majority of their systems are more than 20 years old.\nOne possible explanation for this observation is that monolithic systems are more likely to reach a level of complexity where it becomes too difficult to reliably make changes to the system due to a high degree of coupling (inter-dependency) between components.1 If this is true, it could be the case that relatively few monolithic systems reach an age greater than 20 years before a complete system rewrite is necessary.\n\n\n\n\n\n\nSystem Age Distribution (Stream Aligned)\n\n\n\n\n\n\n\nSystem Age Distribution (IT-Only)\n\n\n\n\n\n\n\n\n\nSystem Age Distribution (Analyst-Only)\n\n\n\n\n\n\n\nSystem Age Distribution (Other Mix)\n\n\n\n\n\nNSOs with IT-Only teams appear relatively less likely to have the majority of systems be less than 20 years old, compared to their Analyst-Only and Stream-Aligned counterparts. One possible explanation is that IT-Only teams are more likely to have the technical skills to perform a full system rewrite when it becomes necessary, although we don’t have sufficient data to say for sure.\nAnother noteworthy observation is that NSOs with Other Mix teams (see Chapter 3) are most likely to have the majority of systems be between 6-10 years old. It is noteworthy that most of the NSOs with Other Mix teams also have Monolithic representative systems, so there is a high degree of overlap between Other Mix teams and Monolithic representative systems.\nOur hypothesis for this observation is that teams comprised of individuals with little shared domain context (e.g., a team with individuals from Corporate IT as well as Domain Analysts) are more likely to produce overly complicated and tightly inter-connected systems that are difficult to change.2 After 6-10 years, these systems become so difficult to maintain that it becomes necessary to undergo a full system rewrite.3"
  },
  {
    "objectID": "system-age-and-updates.html#system-update-frequency",
    "href": "system-age-and-updates.html#system-update-frequency",
    "title": "5  System Age and Updates",
    "section": "5.2 System Update Frequency",
    "text": "5.2 System Update Frequency\nRespondents are presented with the following question.\n\n\n\nAge of Systems Survey Question\n\n\nIn this section, we ask respondents how often the majority of CPI Production Systems are usually updated.\nUnless software is being written in a domain where (1) the problem is “solved” (i.e., requirements never change) and/or (2) the software’s correctness can be proved mathematically, routinely updating systems (e.g., fixing errors in source code or enhancing the system with new features) is a practical reality of software development.\nGiven this practical reality, updating systems at a somewhat high frequency is generally considered to be good practice.4\nWe share below some observations on how frequently respondents update their systems.\n\n\n\n\n\n\nUpdate Frequency Distribution (Overall)\n\n\n\n\n\n\n\nUpdate Frequency Distribution (Monolith)\n\n\n\n\n\n\n\n\n\nUpdate Frequency Distribution (Modular)\n\n\n\n\n\nNSOs with monolithic representative systems are much more likely to never update systems compared to NSOs with Modular representative systems.\nWe suspect this is once again related to the fact that monolithic systems tend to be complex and involve many inter-connected components. In the most extreme case, it can be too risky to update these systems due to the possibility of a change in one part of a system causing unintended consequences in another (seemingly unrelated) part of the system.\nModular systems, in contrast, tend to be easier to reason about, and involve a lower degree of coupling between system components that are unrelated. Hence, making a change to a system component is less likely to lead to an unintended consequence elsewhere in the system.\nAcross all respondents, almost one fifth of respondents indicated that the majority of their systems are never updated. This may be partially due to the fact that some data and methods used with traditional field collection approaches change very rarely. Moreover, these approaches can be very simple to implement in certain cases, which could mean no bugs were ever introduced to the implementation. In such cases, it’s conceivable that non-trivial updates are never performed.5\nMore generally, the distribution of update frequencies seems to be left skewed, with a majority of NSOs having the majority of systems updated once per year or less, or not updated at all.\n\n\n\n\n\n\nUpdate Frequency Distribution (Stream-Aligned)\n\n\n\n\n\n\n\nUpdate Frequency Distribution (IT-Only)\n\n\n\n\n\n\n\n\n\nUpdate Frequency Distribution (Analyst-Only)\n\n\n\n\n\n\n\nUpdate Frequency Distribution (Other Mix)\n\n\n\n\n\nWhen looking at the system age distributions broken down by team type, we do not see much difference from the overall trend. One noteworthy exception to this is the Other Mix team category, which seems to have a relatively high proportion of cases updated less than once per year or not at all.6\n\n\n\n\nEvans, E. 2004. Domain-Driven Design: Tackling Complexity in the Heart of Software. Addison-Wesley. https://books.google.ca/books?id=7dlaMs0SECsC.\n\n\nFord, N., W. M. Richards, P. J. Sadalage, and Z. Dehghani. 2021. Software Architecture: The Hard Parts : Modern Trade-Off Analysis for Distributed Architectures. O’Reilly. https://books.google.ca/books?id=sWNozgEACAAJ.\n\n\nRichards, M., and N. Ford. 2020. Fundamentals of Software Architecture: An Engineering Approach. O’Reilly Media, Incorporated. https://books.google.ca/books?id=_pNdwgEACAAJ."
  },
  {
    "objectID": "system-age-and-updates.html#footnotes",
    "href": "system-age-and-updates.html#footnotes",
    "title": "5  System Age and Updates",
    "section": "",
    "text": "Monolithic architectures are not guaranteed to result in highly coupled systems. However, it requires considerable effort, skill, and knowledge of software architecture patterns to ensure monolithic architectures remain loosely coupled over a long period of time (Ford et al. (2021)).↩︎\nIn our experience, these systems become overly complicated because of the need to introduce new abstractions to bridge the lack of shared domain context. These abstractions aren’t necessary when all parties involved have a common understanding of the domain problem.↩︎\nThis hypothesis is consistent with our professional experience and prior knowledge in software architecture (e.g., Evans (2004), Ford et al. (2021), Richards and Ford (2020)). However, it is important to note that this particular observation is made on a relatively small subset of our survey data, so it could be an anomaly.↩︎\nN.B., having the ability to update systems at a high frequency is unambiguously good practice.↩︎\nAnother possibility is that some systems are never updated because there was only one individual who knew how the system worked, and that individual has since left the organization, so the system can no longer be updated. We did not collect sufficient data to diagnose why this one fifth of NSOs never update their systems, so we cannot say for sure what the explanation is one way or the other.↩︎\nOnce again, we note the small sample size caveat of NSOs containing Other Mix teams.↩︎"
  },
  {
    "objectID": "number-of-individuals.html#number-of-people-small-changes",
    "href": "number-of-individuals.html#number-of-people-small-changes",
    "title": "6  Number of People",
    "section": "6.1 Number of People (Small Changes)",
    "text": "6.1 Number of People (Small Changes)\nRespondents are presented with the following question.\n\n\n\nNumber of Individuals for small changes\n\n\n\n\n\n\n\n\nNumber of Individuals for Small Changes (Overall)\n\n\n\n\n\n\n\nNumber of Individuals for Small Changes (Monolith)\n\n\n\n\n\n\n\n\n\nNumber of Individuals for Small Changes (Modular)\n\n\n\n\n\nOverall, the majority of respondents indicate between 1-3 individuals needing to be involved with small changes, while a minority indicate that 4 or more individuals need to be involved with small changes.\nOur sense is that 1-3 individuals participating in a small change is reasonable. For low risk small changes, one person could make the change in isolation, while for more important small changes, one or two individuals could quickly peer review the change before it is implemented.\nIt appears that NSOs with Hybrid or Modular representative systems are slightly more likely to involve 4-6 individuals in small changes compared to NSOs with Monolithic representative systems.\nOur suspicion here is that NSOs with Hybrid or Modular representative systems are more likely to have “interface boundaries” between systems maintained by two or more distinct teams. If this is the case, certain small changes may require input from individuals across two or more teams. This is not necessarily unreasonable. If system and team boundaries are well defined, communication about small changes to a system can still be efficient even if a slightly greater number of individuals need to be made aware of the small change.\nThere are no significant differences in the number of individuals required for small changes between the various team types."
  },
  {
    "objectID": "number-of-individuals.html#number-of-people-large-changes",
    "href": "number-of-individuals.html#number-of-people-large-changes",
    "title": "6  Number of People",
    "section": "6.2 Number of People (Large Changes)",
    "text": "6.2 Number of People (Large Changes)\nRespondents are presented with the following question.\n\n\n\nNumber of Individuals for large changes\n\n\n\n\n\n\n\n\nNumber of Individuals for Large Changes (Overall)\n\n\n\n\n\n\n\nNumber of Individuals for Large Changes (Monolith)\n\n\n\n\n\n\n\n\n\nNumber of Individuals for Large Changes (Modular)\n\n\n\n\n\nUnsurprisingly, more individuals are required to participate in large changes than small changes. It appears that the majority of respondents require between 2-6 individuals to participate in a large change to a system.\nInterestingly, there is not a significant difference in the number of people required for large changes between NSOs with Monolithic representative systems and NSOs with Modular representative systems. Moreover, there is also no meaningful difference in this metric between the various team compositions.\nWe were a bit surprised by this finding, as we expected that certain team compositions and system architectures would be associated with differing numbers of people who need to participate in large changes.\nOur hypothesis here is that the number of people required to participate in large changes is probably a function of organization size more than anything else. For example, if the size of all teams involved in a large change for a small NSO is 6, then it would be impossible for the total number of individuals to exceed 6, regardless of the CPI System architecture or the team compositions."
  },
  {
    "objectID": "change-lead-times.html#lead-time-small-changes",
    "href": "change-lead-times.html#lead-time-small-changes",
    "title": "7  Lead Time",
    "section": "7.1 Lead Time (Small Changes)",
    "text": "7.1 Lead Time (Small Changes)\nRespondents are presented with the following question.\n\n\n\nLead times for small changes\n\n\n\n\n\n\n\n\nLead Time for Small Changes (Overall)\n\n\n\n\n\n\n\nLead Time for Small Changes (Monolith)\n\n\n\n\n\n\n\n\n\nLead Time for Small Changes (Modular)\n\n\n\n\n\nOverall, the majority of lead times for small changes are between 1 day and 1 week, with a minority of respondents indicating small changes happening within 3 months (i.e., 3 months or less).\nOur expectation is that small changes of the magnitude we described in the question prompt should take teams at most a few days to implement, test, and integrate into production systems. We were a bit surprised to see a non-trivial fraction of the sample reporting lead times of “Within 1 month” or “Within 3 months” for small changes.\nIt is also noteworthy that NSOs with monolithic representative systems were more likely to report lead times for small changes of “Within 1 day”, whereas NSOs with modular representative systems were more likely to report lead times for small changes of “Within 1 week”.\nOur hypothesis here is that, by definition, a modular representative system is more likely than a monolithic representative system to span two or more teams. Therefore, small changes may still need to be reviewed by a member on each team. It is reasonable that it might take more than one business day to find a time where the various team members are available to meet, so this alone could cause a small change to take more than one day.\nIn either case, our view is that “Within 1 day” and “Within 1 week” are both reasonable answers to this question.\n\n\n\n\n\n\nLead Time for Small Changes (Stream-Aligned)\n\n\n\n\n\n\n\nLead Time for Small Changes (IT-Only)\n\n\n\n\n\n\n\n\n\nLead Time for Small Changes (Analyst-Only)\n\n\n\n\n\n\n\nLead Time for Small Changes (Other Mix)\n\n\n\n\n\nWith respect to team composition, Stream-Aligned teams, IT-Only teams, and Analyst-Only teams had lead time distributions that were close to the overall lead time distribution. The most common response for Other Mix teams is “Within 1 month”, but the sample size for this team type is too small to conclude anything meaningful here."
  },
  {
    "objectID": "change-lead-times.html#lead-time-large-changes",
    "href": "change-lead-times.html#lead-time-large-changes",
    "title": "7  Lead Time",
    "section": "7.2 Lead Time (Large Changes)",
    "text": "7.2 Lead Time (Large Changes)\nRespondents are presented with the following question.\n\n\n\nLead times for large changes\n\n\n\n\n\n\n\n\nLead Time for Large Changes (Overall)\n\n\n\n\n\n\n\nLead Time for Large Changes (Monolith)\n\n\n\n\n\n\n\n\n\nLead Time for Large Changes (Modular)\n\n\n\n\n\nOverall, the lead time for large changes was very right skewed, with the most common response being that large changes happen “Within 1 month”.\nIt is interesting that, unlike with small changes, NSOs with Monolithic representative systems are more likely to report lead times of “Within 1 year” or “More than 1 year”, and they are also more likely to report an answer of “Too complex” or “Can’t be modified”.2\nThis result is consistent with industry knowledge (Ford et al. (2021), Richards and Ford (2020)) as well as earlier findings in this report (e.g., sec-age). Monolithic systems are more likely to have components that are highly coupled (inter-connected) compared to modular systems. This high degree of coupling not only makes it more difficult to reason through changes to the system, but it also requires more rigorous testing to ensure that a large change doesn’t break a seemingly unrelated component. Therefore, it is not surprising to observe that NSOs with monolithic representative systems are more likely to report higher lead times compared to NSOs with Modular representative systems.\n\n\n\n\n\n\nLead Time for Small Changes (Stream-Aligned)\n\n\n\n\n\n\n\nLead Time for Small Changes (IT-Only)\n\n\n\n\n\n\n\n\n\nLead Time for Small Changes (Analyst-Only)\n\n\n\n\n\n\n\nLead Time for Small Changes (Other Mix)\n\n\n\n\n\nWhen looking at the distribution of lead times for large changes by team type, there are several noteworthy observations.\nFirst, Stream-Aligned teams and Analyst-Only teams were more likely to report lead times of “Within 1 month” compared to any other answer. Stream-Aligned teams and Analyst-Only teams were a bit more likely to report shorter lead times compared to IT-Only teams, and were much more likely to report shorter lead times compared to Other Mix teams.\nThis finding is consistent with the work of Skelton, Pais, and Malan (2019), which suggests that Stream-Aligned teams organized around an end-to-end slice of a particular business domain tend to move faster.3\nIt is also worth noting that “More than 1 year” is a somewhat common answer across all team types, suggesting that a fraction of NSOs probably struggle with high lead times for reasons other than team types.\nWe hypothesize that the lack of shared domain context in Other Mix teams could explain why their reported lead times are much higher than the other 3 team types. As discussed in Chapter 5, the lack of a shared domain context increases communication overhead as all parties involved need to spend additional time bridging knowledge gaps. This extra communication overhead could extend each step of the system development process, leading to longer lead times overall.\n\n\n\n\nFord, N., W. M. Richards, P. J. Sadalage, and Z. Dehghani. 2021. Software Architecture: The Hard Parts : Modern Trade-Off Analysis for Distributed Architectures. O’Reilly. https://books.google.ca/books?id=sWNozgEACAAJ.\n\n\nForsgren, N., J. Humble, and G. Kim. 2018. Accelerate: The Science Behind DevOps : Building and Scaling High Performing Technology Organizations. G - Reference,information and Interdisciplinary Subjects Series. IT Revolution. https://books.google.ca/books?id=85XHAQAACAAJ.\n\n\nRichards, M., and N. Ford. 2020. Fundamentals of Software Architecture: An Engineering Approach. O’Reilly Media, Incorporated. https://books.google.ca/books?id=_pNdwgEACAAJ.\n\n\nSkelton, M., M. Pais, and R. Malan. 2019. Team Topologies: Organizing Business and Technology Teams for Fast Flow. G - Reference,information and Interdisciplinary Subjects Series. IT Revolution. https://books.google.ca/books?id=oFdRuAEACAAJ."
  },
  {
    "objectID": "change-lead-times.html#footnotes",
    "href": "change-lead-times.html#footnotes",
    "title": "7  Lead Time",
    "section": "",
    "text": "One important point to note here is that short lead times are good as long as a certain minimum standard of quality is met. For instance, shorter lead times are not necessarily better if they are associated with a significant drop in the quality of the output.↩︎\nFor confidentiality reasons, we grouped “Too complex” and “Can’t be modified” into one category in the figures on this page.↩︎\nWe are glossing over a lot of nuance here for simplicity. For readers who are interested in a more comprehensive overview of the work of Skelton, Pais, and Malan (2019), we recommend reading through the Team Topologies Key Concepts website.↩︎"
  },
  {
    "objectID": "alternative-data.html#alternative-data-usage",
    "href": "alternative-data.html#alternative-data-usage",
    "title": "8  Alternative Data",
    "section": "8.1 Alternative Data Usage",
    "text": "8.1 Alternative Data Usage\nJust under two thirds of respondents report not using alternative data sources at all. Of those that use alternative data sources, the majority of respondents report that “Less than 10%” or “Between 10% and 30%” of their CPI is derived from alternative data sources.3\n\n\n\n\n\nOf those NSOs that don’t currently use alternative data sources, almost three quarters of them report that they would like to use alternative data sources. Of those NSOs that would like to use alternative data sources, we asked them how much alternative data they would like to use in their CPI Production Systems in an ideal scenario. We show this distribution below.\n\n\nWarning in geom_bar(binwidth = 1, colour = \"black\", fill = \"white\"): Ignoring\nunknown parameters: `binwidth`\n\n\n\n\n\nIt appears that most NSOs want between 10% and 50% of their CPI to be comprised of alternative data sources (by expenditure weight). Our suspicion is that leveraging alternative data may be challenging for certain components of the CPI, so even in an ideal scenario, NSOs may prefer to continue using field collected data for quality reasons."
  },
  {
    "objectID": "alternative-data.html#which-price-index-methods-are-used-on-alternative-data-sources",
    "href": "alternative-data.html#which-price-index-methods-are-used-on-alternative-data-sources",
    "title": "8  Alternative Data",
    "section": "8.2 Which Price Index Methods are Used on Alternative Data Sources",
    "text": "8.2 Which Price Index Methods are Used on Alternative Data Sources\nOf those respondents reporting that they currently use alternative data sources, we asked which price index methods are most commonly used.4 The table below summarizes the number of respondents who are using each method.5\n\n\n\n\n\nGEKS\n6\n\n\nTime Dummy Hedonic\n4\n\n\nHedonic\n6\n\n\nOther Multilateral\n&lt; 3\n\n\nDynamic Sample\n5\n\n\nFixed Sample\n16\n\n\nOther\n7"
  },
  {
    "objectID": "alternative-data.html#what-challenges-are-faced-in-the-adoption-of-alternative-data",
    "href": "alternative-data.html#what-challenges-are-faced-in-the-adoption-of-alternative-data",
    "title": "8  Alternative Data",
    "section": "8.3 What Challenges are Faced in the Adoption of Alternative Data",
    "text": "8.3 What Challenges are Faced in the Adoption of Alternative Data\nWe asked all respondents to rank the challenges they face in adopting alternative data sources(regardless of whether or not they are currently using alternative data in their CPI Production Systems).\n\n\n\n\n\n\nRanked Alternative Data Challenges\n\n\n\n\n\nSome alternative data challenges will be region-specific, such as lack of cooperation from data providers, authority to collect alternative data, and availability of alternative data.\nHowever, some commonly cited issues such as Insufficient Skills and Methodology Knowledge can be addressed in part by effective knowledge sharing from domain experts."
  },
  {
    "objectID": "alternative-data.html#footnotes",
    "href": "alternative-data.html#footnotes",
    "title": "8  Alternative Data",
    "section": "",
    "text": "See the UN e-handbook for an overview of how alternative data sources (also referred to as new data sources) are used.↩︎\nFor example, if a retailer agrees to share data with a NSO, the retailer can quite easily send weekly snapshots of their product transaction records. This dataset is much larger than anything that could realistically be collected by a field collection agent, but it also introduces new statistical issues (e.g., sample selection), and special tooling may be required to work with a dataset of this size.↩︎\nThese percentages refer to the share of the CPI by expenditure weight. For example, if an NSO uses alternative data sources to calculate the CPI for product categories that make up 10% of total household expenditures, then we would say that 10% of the CPI comes from alternative data sources.↩︎\nFor readers who are unfamiliar with the Consumer Prices business domain, these are techniques that are used to calculate period-over-period price changes from a given data source.↩︎\nThese choices are not mutually exclusive; one NSO may use multiple price index methods.↩︎"
  },
  {
    "objectID": "challenges.html#footnotes",
    "href": "challenges.html#footnotes",
    "title": "9  Challenges",
    "section": "",
    "text": "The problem of passing data inputs from one system to another system has been around since the dawn of computing. However, the somewhat new concept of Data Contracts (see Data Contract Specification, for example) tries to address this problem in the context of passing complex structured data between data producers and data consumers.↩︎\nFor example, adopting a few simple ideas such as grouping related functions into the same module or separating configuration information source code can lead to significant simplifications to code bases that don’t currently leverage these ideas.↩︎\nFor example, a 1,000 line Python script that performs multiple operations on a Pandas data frame entirely in the global scope will not integrate nicely with a testing framework like PyTest. This is because there is no straightforward way to identify and group a section of the code to be run in a test.↩︎"
  },
  {
    "objectID": "findings-and-next-steps.html#bottom-line-up-front",
    "href": "findings-and-next-steps.html#bottom-line-up-front",
    "title": "10  Conclusion",
    "section": "10.1 Bottom Line Up Front",
    "text": "10.1 Bottom Line Up Front\nThis section highlights some of the noteworthy results we found in our survey on CPI Production Systems.\n\n10.1.1 System and Team Organization\n\nThe two most common ways that system components are coupled across GSBPM steps are (1) to have one system span both the data ingestion step and the data processing step, and (2) to have one system span all 5 GSBPM steps.\nBy far the most common team structure we found was comprised only of domain-embedded analysts. The second most common team structure we found was a mix of Corporate IT employees and domain-embedded analysts.\nTeams of domain-embedded analysts and domain-embedded IT professionals were not very common, suggesting that it is not common practice to embed IT staff within a business domain team. In other words, IT expertise tends to be centralized rather than embedded in business domain teams, which may contribute to increased communication overhead due to centralized IT staff lacking important business domain context.\nUsing the “Representative System Group” question, we were able to elicit a high-level description of the system and team organization for a representative group of CPI Production Systems at the respondent’s organization. While this system/team description was high level, it provided us with enough information to loosely group NSOs into 3 architecture categories (Monolithic, Hybrid, Modular) and 4 team categories (Stream-Aligned, IT-Only, Analyst-Only, Other Mix).\nIT-Only teams were the most likely to develop Modular Systems compared to the other 3 team types.\nThe most common architecture type overall was Monolithic.\nOther Mix teams were much more likely to develop Monolithic systems compared to the other 3 team types.1\n\n\n\n10.1.2 Tools and Technologies\n\nA majority of respondents surveyed don’t use any kind of Version Control System at all. The second most common answer was GitLab/GitHub, and the third most common version control strategy was to use “File Naming Conventions”.\nMicrosoft Excel was by far the most commonly used commercial software product in CPI Production System teams. The next most common product used was SAS, and the third most commonly used product is Microsoft Access.\nThe most common tool used for project management was a shared Microsoft Excel workbook, while the second most common response was to not use any software for project management.\nThe most common programming language used across all systems is SQL, while the second most frequently used language R, with Python and SAS close behind.\nAmong organizations with Monolithic representative systems, SQL is still the most commonly used language, with many other languages being reported. For example, Java, Python, Visual Basic Applications, R, Visual Basic, SAS, C#, and C++ are all being used by multiple organizations.\nAmong organizations with Modular representative systems, R and SAS are tied for first place, with SQL in a close second. The only other responses with more than a couple of occurrences are “None” (i.e., no programming language is used), Python, and Visual Basic Applications.\nBy far the most commonly used storage formats were (1) Database Management Systems (DBMS) and (2) file systems, with the former having a slightly higher occurrence.\nVery few respondents reported leveraging analytics-optimized file formats such as Apache Parquet, and very few respondents reported using Object Storage solutions such as Amazon S3 or Azure Data Lake Storage.\n\n\n\n10.1.3 System Age and Updates\n\nOrganizations with Monolithic representative systems are most likely to report a system age of 6-10 years or 11-20 years, while organizations with Modular representative systems are equally likely to report any of the system ages provided.\nIT-Only teams were much less likely to report a system age of “more than 20 years” compared to Stream Aligned teams and Analyst-Only teams.\nOther Mix teams were much more likely to report a system age of 6-10 years compared to any of the other options.\nOrganizations with Monolithic representative systems were much more likely to report that the majority of systems that are never updated compared to organizations with Modular representative systems.\nOverall, the most common answers for how often the majority of systems are updated were (1) less than once per year, (2) never updated, and (3) once per year.\nStream-Aligned teams were the most likely to report that the majority of systems are never updated, with all other team types reporting this answer multiple times.2 Updating systems less than once per year was the most common answer across all team types.\nOther Mix teams didn’t report any update frequency that was more frequent than every six months.\n\n\n\n10.1.4 Number of People\n\nMost small changes require the participation of 2-3 individuals, with answers of “1 individual” and “4-6 individuals” also being somewhat common.\nOrganizations with monolithic representative systems were slightly more likely to report a smaller number of individuals participating in small changes compared to organizations with modular representative systems.\nOrganizations with monolithic representative systems were most likely to require participation of 4-6 individuals or 2-3 individuals for large changes, whereas organizations with modular representative systems were most likely to report requiring participation of 2-3 individuals. For both architecture types, there were a roughly equal number of answers requiring 7-9 individuals or more for large changes.\n\n\n\n10.1.5 Lead Times\n\nThe most common responses overall were lead times of “within 1 week” or “within 1 day” for small changes. However, a non-trivial fraction of respondents reported lead times of “within 1 month” or “within 3 months” for small changes.\nThere was no meaningful difference between architecture types or team types for lead times on small changes.\nOrganizations with monolithic representative systems were more likely to report lead times of “within 1 year” or “more than 1 year” for large changes compared to organizations with modular representative systems. A few respondents from organizations with monolithic representative systems reported that large changes were “too complex” or “the system can’t be modified”, whereas zero respondents from organizations with modular representative systems reported either of these answers.\nThe most common lead time for large changes by far among organizations with stream-aligned teams was “within 1 month”, whereas IT-Only teams were almost equally likely to report “within 1 week”, “within 1 month”, “within 3 months”, or “more than 1 year”.\nOther Mix teams reported the longest lead times for large changes, with every lead time reported being “within 1 month” or longer.\nAcross all team types, “within 1 year” and “more than 1 year” were somewhat common answers to the question about lead times for large changes.\n\n\n\n10.1.6 Alternative Data Usage\n\nJust under two thirds of respondents report not using alternative data at all.\nOf those respondents that do use alternative data, the majority of respondents report that “less than 10%” or “between 10% and 30%” of their CPI is comprised of alternative data by expenditure weight.\nOf those respondents that don’t use alternative data, almost three quarters of them report that they would like to use alternative data.\nThe most commonly cited challenges with respect to alternative data adoption are (1) lack of data provider cooperation, (2) insufficient capacity, and (3) insufficient skills to work with alternative data.\n\n\n\n10.1.7 Overall Challenges Faced\n\nThe most commonly cited challenge by far was “lack of staff”, followed by “lack of skills maintaining complex systems” and “system interactions” in second and third place.\nTied for fourth place are (1) managing complexity within a system (e.g., maintaining large quantities of code) and (2) verifying that a system behaves correctly.\nAlmost noone cited “version control” as a challenge they faced, despite the majority of respondents indicating that they do not use any kind of version control solution or file naming conventions.3"
  },
  {
    "objectID": "findings-and-next-steps.html#practical-suggestions",
    "href": "findings-and-next-steps.html#practical-suggestions",
    "title": "10  Conclusion",
    "section": "10.2 Practical Suggestions",
    "text": "10.2 Practical Suggestions\nBased on our survey results, we have several concrete and practical suggestions that may help the teams responsible for CPI Production Systems to manage complexity and reduce maintenance burden for these systems. While this guidance is targeted at the audience of this survey, our suspicion is that other teams managing similar Complex Analytical Systems may benefit from applying a number of the suggestions in this section.\n\n\n\n\n\n\nImportant\n\n\n\nAll of these suggestions are guidelines based on correlational evidence and general industry knowledge.\nWe are not claiming any strict cause-and-effect relationships from this survey alone. Rather, our goal is to encourage readers to think critically about these suggestions and to pursue suggestions that resonate based on their own experiences.\n\n\n\nPractical Takeaways from Survey\n\n\n\n\n\n\nSuggestion\nExplanation\n\n\n\n\nThink explicitly about system boundaries.\nThere is some evidence in our survey that monolithic architectures are associated with certain outcomes such as (1) longer lead times for large changes and (2) never updating systems.   Are two unrelated technical capabilities implemented in the same system? Would it be easier to maintain your codebase if these technical capabilities were split into two independent components?\n\n\nThink explicitly about data interchange between systems.\nIf an important piece of data is exchanged between two or more systems, take the time to properly document important properties of the data such as the columns available, the data types, and the semantics of the data. This will make it easier for data consumers to use this data.   One way to formalize this data exchange is through a standard format such as Data Contract Specification.\n\n\nEmbed technical expertise in business domain teams.\nThere is some evidence in our survey that “Other Mix” teams underperformed the other team mixes on several outcomes.   Effectively developing and maintaining CPI Production Systems requires a team of individuals with both strong domain knowledge and strong technical skills.   Whether technical expertise is embedded by directly employing IT professionals within the business domain team, or by upskilling domain-embedded analysts to improve their technical skills, our belief is that improving the technical capacity of business domain teams who own CPI Production Systems will lead to a number of improved business outcomes.\n\n\nAdopt Git and GitLab or GitHub as a Version Control System for code, configuration, and documentation.\nThe cognitive load of understanding CPI Production Systems is already high enough without manually keeping track of version control and code integration from multiple collaborators. Allow a purpose-built tool handle the burden of revision control.\n\n\nLeverage analytics optimized file formats like Apache Parquet\nAdopting a columnar file format like Parquet along with a handful of best practices makes it feasible to work with larger than memory datasets on a single machine. For example, if you only need to use 3 out of 50 columns of a table for a particular task, you can load tens of millions of records into memory on a modest commodity computer.4 You can then work with this data using an industry standard data manipulation library such as Python’s Pandas, Apache Arrow, or R Data Frames to name a few.\n\n\nWhere it’s feasible, implement Complex Analytical Systems as pipelines with one-way data flows and idempotent operations.\nIf you can model your flow of change as directed acyclic graph (DAG) where nodes represent the state of data and edges between nodes represent idempotent operations, it is possible to significantly reduce the complexity of state management in your Complex Analytical System.A practical example of this concept is a data processing workflow that involves an upsert operation to update records5. If a batch of data contains records that are not in the original table, they will be inserted into the table, otherwise they will be updated in the table. What makes this operation idempotent is the fact that the same batch of data can be upserted to the table multiple times and the final result will be the same as if this operation happened only once.\n\n\nPractice updating systems more frequently.\nIn software engineering, there is a commonly used performance metric called Deployment Frequency (Forsgren, Humble, and Kim (2018)), which measures how frequently code is deployed to production.   The closest analog to this concept in the world of CPI Production Systems is what we’ve been referring to as “Update Frequency” throughout this report. The rationale for deployment frequency is that it’s better to deploy many small and safe changes regularly than to deploy big risky changes infrequently.   There are limits to how far this can be taken with CPI Production Systems, however, our belief is that frequently updating and testing systems with small changes leads to fewer unforeseen issues when it comes time to release a change for production.6\n\n\nEnsure your CPI Production System can operate in a separate development environment.\nWhen dealing with complex systems, it is critical to have a safe environment where teams can “move fast and break things” without any risk to the production version of the system.7   This is in contrast to only having the live production system to perform tests on, in which case one needs to be absolutely certain that a change won’t irreparably break the live production system. In extreme cases, this proposition is so risky that the production system is never updated at all."
  },
  {
    "objectID": "findings-and-next-steps.html#future-work",
    "href": "findings-and-next-steps.html#future-work",
    "title": "10  Conclusion",
    "section": "10.3 Future Work",
    "text": "10.3 Future Work\nWe believe there are many areas of future work on this topic, but for brevity, we attempt to summarize them into two main categories below.\nFirst, as mentioned at the beginning of this report, teams maintaining Complex Analytical Systems often struggle with many aspects of managing system complexity.\nWhat is noteworthy is that none of these system complexity challenges are unsolved problems. As we note several times throughout our report, these problems have been examined extensively in other disciplines such as software engineering, and satisfactory solutions to these problems have often existed for decades.\nMoreover, there is an abundance of freely available online material to teach these best practices, and there are often open source software products that address many of these challenges as well. There are even initiatives such as Reproducible Analytical Pipelines (RAP) (NHS (2017)) which actively curate the most relevant software engineering concepts for the kind of work required by Complex Analytical Systems.\nDespite all of this, at the time of producing this report (April, 2025), effectively managing Complex Analytical Systems seems to be far from a solved problem. To this end, we think there is significant value in understanding the reasons this gap is so difficult to bridge. Importantly, is there a communication gap that can be bridged by more effectively connecting business domain analysts with the relevant content, or is the issue related to cognitive load or some other constraint limiting the bandwidth of these business domain teams?\nSecond, are there improvements that can be made to both (1) system architecture and (2) team organization for Complex Analytical Systems in order to improve business outcomes? For example, to what extent has Conway’s Law impacted the architecture of Complex Analytical Systems such as the CPI Production Systems studied in this report? Would different team structures and team interaction modes lead to more effective system architectures?\nOur survey provides some evidence that certain findings from the world of software engineering regarding team organization and system architecture may indeed be applicable to Complex Analytical Systems. However, the evidence from this survey alone is insufficient to make any sweeping generalizations about Complex Analytical Systems as a whole.\nTo this end, we believe there is significant business value to be gained by further investigating these topics in the context of other business domains maintaining Complex Analytical Systems.8"
  },
  {
    "objectID": "findings-and-next-steps.html#footnotes",
    "href": "findings-and-next-steps.html#footnotes",
    "title": "10  Conclusion",
    "section": "",
    "text": "Note that there is a small sample size caveat with observations involving Other Mix teams. Had the sample size been larger, the observations we observed with this team type may not have been as extreme as what we observed in the survey.↩︎\nWe suspect that this is slightly biased by the fact that the majority of Stream-Aligned teams in our sample are comprised of domain-analysts only rather than having both domain-embedded analysts and domain-embedded IT professionals.↩︎\nWe are skeptical that these two facts can be true at the same time. Our suspicion is that some respondents have not explicitly thought about version control as a distinct problem with purpose-built tooling that exists to solve it.↩︎\nWhen working with this quantity of data, it is important to pay attention to the data types of each column and to choose the most parsimonious data types. For example, if 3 columns can be correctly represented with boolean, 16-bit integer, and 32-bit integer data types, there are significant memory savings to be gained by casting the variables to these types upfront.↩︎\nUPSERT is a portmanteau of the common INSERT and UPDATE database operations.↩︎\nIn general, the Consumer Price Index is a non-revisable product, meaning that it is not straightforward to “roll back” a change in the same way that would be possible in other non-critical operations or for statistical products that have a revision policy. Because of this, there is a certain level of due-diligence required for large system changes, meaning there are some limits on how frequently CPI Production Systems can be updated.↩︎\nNote that this can be as simple as having a production folder and a development folder on a network file system and scoping activities to the appropriate folder. More complex separations of development, testing, and production environments are possible, but we encourage readers to start simple if this is a new concept.↩︎\nFor example, if there is evidence that certain team structures, team interaction modes, and system architectures are more effective than others, then organizations that adopt the improved team topologies and system architectures may see reduced maintenance costs and faster delivery times, among other benefits.↩︎"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Dehghani, Z. 2022. Data Mesh: Delivering Data-Driven Value at\nScale. O’Reilly. https://books.google.ca/books?id=M5J5zgEACAAJ.\n\n\nEvans, E. 2004. Domain-Driven Design: Tackling Complexity in the\nHeart of Software. Addison-Wesley. https://books.google.ca/books?id=7dlaMs0SECsC.\n\n\nFord, N., W. M. Richards, P. J. Sadalage, and Z. Dehghani. 2021.\nSoftware Architecture: The Hard Parts : Modern Trade-Off Analysis\nfor Distributed Architectures. O’Reilly. https://books.google.ca/books?id=sWNozgEACAAJ.\n\n\nForsgren, N., J. Humble, and G. Kim. 2018. Accelerate: The Science\nBehind DevOps : Building and Scaling High Performing Technology\nOrganizations. G - Reference,information and Interdisciplinary\nSubjects Series. IT Revolution. https://books.google.ca/books?id=85XHAQAACAAJ.\n\n\nNHS. 2017. “Reproducible Analytical Pipelines (RAP).” https://nhsdigital.github.io/rap-community-of-practice/.\n\n\nPrice, M., and D. Marques. 2023. “Developing Reproducible\nAnalytical Pipelines for the Transformation of Consumer Price\nStatistics: Rail Fares.” Office of National Statistics; \"https://unece.org/sites/default/files/2023-05/7.4%20UK_un_systems_railfares_paper.pdf\".\n\n\nRichards, M., and N. Ford. 2020. Fundamentals of Software\nArchitecture: An Engineering Approach. O’Reilly Media,\nIncorporated. https://books.google.ca/books?id=_pNdwgEACAAJ.\n\n\nSkelton, M., M. Pais, and R. Malan. 2019. Team Topologies:\nOrganizing Business and Technology Teams for Fast Flow. G -\nReference,information and Interdisciplinary Subjects Series. IT\nRevolution. https://books.google.ca/books?id=oFdRuAEACAAJ."
  },
  {
    "objectID": "intro.html#the-survey-process-and-aspects-of-the-collected-data",
    "href": "intro.html#the-survey-process-and-aspects-of-the-collected-data",
    "title": "1  Introduction",
    "section": "1.5 The survey process and aspects of the collected data",
    "text": "1.5 The survey process and aspects of the collected data\nWe developed this survey during the fall of 2024 and administered it through the winter of 2025. With support from the UN-CEBD and UNECE, we contacted NSOs around the world. We prioritized reaching out directly to individuals in Price Statistics divisions at each NSOs, or where no contact was known, we inquired with the overall organization and requested that the survey link be forwarded to the Price Statistics team of that organization. Individuals were asked to submit one response from the organization, and where applicable, data editing was done to ensure a robust dataset was finalized.\nAround 70 NSOs responded to the survey. Every major geographic region of the world is represented in the survey. NSOs that answered included those advanced in their modernization and the use of new data sources and those that focused on traditional methods. Self-selection bias is possible (this could also be due to factors such as the time commitment necessary and the complexity of the survey). It is also possible that misinterpretation could have affected some responder answers, which we note when discussing specific topics. In summary though, despite the likelihood for self-selection bias and some misinterpretation of the questions asked, we believe the coverage is good."
  },
  {
    "objectID": "index.html#preface",
    "href": "index.html#preface",
    "title": "Interim Report: Survey of CPI Production Systems",
    "section": "Preface",
    "text": "Preface\nThis work showcases the findings and takeaways from surveying National Statistical Organizations (NSOs) around the world during the winter of 2025. The survey primarily focused on how each NSO structures, develops, and maintains their Consumer Price Index (CPI) production systems and organizes the teams that are responsible for these systems.\n\n\n\nThis work was done by Workstream 4 (CPI Systems and Architecture), which is part of the UN Task Team on Scanner Data. Hence, we would like to acknowledge the team members of Workstream 4 who provided insights, helped draft survey questions, and supported this empirical assessment.\n\n\n\n\n\n\nWe would also like to thank and acknowledge the support of the Steering Group of the UN Task Team on Scanner Data, as well as the UN Committee of Experts on Big Data and Data Science for Official Statistics (UN-CEBD) team in making this work possible. Without the support of both, it would not have been possible to survey NSOs around the world and evaluate their CPI production system architectures and team organizations."
  },
  {
    "objectID": "index.html#survey-methodology-notes",
    "href": "index.html#survey-methodology-notes",
    "title": "Interim Report: Survey of CPI Production Systems",
    "section": "Survey Methodology Notes",
    "text": "Survey Methodology Notes\n\n70 NSOs around the world responded to our survey by the time this interim report was released.\nThis survey was administered using LimeSurvey, and the questionnaire used can be found in the Github repository for this survey.\nTo preserve anonymity, we do not disclose any values if there are 2 or fewer respondents that take on the value. As a result, throughout the report, certain tables and figures may be presented in a way where certain categories are omitted or grouped together."
  },
  {
    "objectID": "index.html#sec-motivation",
    "href": "index.html#sec-motivation",
    "title": "Interim Report: Survey of CPI Production Systems",
    "section": "1.3 Motivation",
    "text": "1.3 Motivation\nIn our time working at NSOs, we have encountered some extremely complicated systems that exist in order to produce various analytical and data products such as consumer price indexes, national accounts figures, or labour force statistics. These complicated systems and the teams who maintain them are the subjects of this survey and write up. To reduce ambiguity, we refer to these systems as Complex Analytical Systems throughout this report.\nComplex Analytical Systems involve significant amounts of code, documentation, and other non-code artifacts such as Excel Workbooks that carry out complex business logic in order to transform input data into output data. Additionally, they are often developed entirely or in large part by people with backgrounds in Economics, Statistics, Mathematics, or another area related to the domain of Official Statistics.\nThese Complex Analytical Systems differ from traditional software systems in a number of important aspects4:\n\n\n\n\n\n\n\nComplex Analytical Systems\nTypical Software System\n\n\n\n\nMultiple distinct scripts that are run sequentially and perform complex data manipulations.\nOne code base representing an entire application.\n\n\nRunning time measured in minutes/hours\nRunning time measured in milliseconds.\n\n\nHuman in the loop activities to interpret results.\nCompletely autonomous system.\n\n\nAd-hoc (messy) data gathered from whatever data sources are available.\nHighly structured data whose schema is designed in lock step with the rest of the system.\n\n\nBatch workloads that are run manually (or semi-manually).\nSystem running continuously in an event loop waiting for user input.\n\n\nOperate on a large fraction of an entire table quickly.\nSearch for one specific record in a large table quickly.\n\n\n\nDue to differences like those mentioned above, there is not a perfect mapping between best practices from the software engineering world and pain points currently experienced by teams maintaining Complex Analytical Systems. However, there are certainly some best practices from software engineering that are highly appropriate to solve some of the problems faced in the development and maintenance of Complex Analytical Systems.\nTo this end, we hope our survey can help bridge the gap between well-understood industry best practices from the world of software engineering, and those aspects of Complex Analytical Systems that could benefit from these best practices. Our hope is that the insights gained and the survey methodology deployed may be valuable for other Complex Analytical Systems facing similar challenges."
  },
  {
    "objectID": "index.html#sec-why-run-this-survey",
    "href": "index.html#sec-why-run-this-survey",
    "title": "Interim Report: Survey of CPI Production Systems",
    "section": "1.4 What Was the Purpose of This Survey?",
    "text": "1.4 What Was the Purpose of This Survey?\nIn our experience, we’ve noticed that many teams who are responsible for Complex Analytical Systems struggle with managing many aspects of system complexity.\nComplex Analytical System business domain teams are typically comprised of individuals with strong analytical skills and significant domain knowledge, however, they often do not have specific training in software engineering concepts. Therefore, they are often not exposed to the significant body of knowledge that has been developed over decades to deal with the kinds of system complexity problems that software developers are routinely exposed to.\nWe have also found that individuals in these business domains are often missing the vocabulary and concepts to articulate the state of their Complex Analytical Systems. As a result, when these individuals try to explain where they are struggling to a more IT-oriented audience, miscommunication often results, and it becomes difficult to arrive at reasonable solutions.\nIn this survey, we ask questions that capture several germane aspects of system organization, team organization, technology choices, and business outcomes using language, terms, and conceptual models that are more familiar to individuals on these business domain teams. Our rationale for doing this is threefold.\n\nMeasure and describe the state of many Complex Analytical Systems around the world within a specific business domain (CPI Production Systems).\nProvide some concrete and practical suggestions to address common areas of struggle within this domain across many NSOs.\nExpose people from these business domain teams to software engineering concepts that are relevant in the development and maintenance of Complex Analytical Systems.\n\nWhile this report is tailored towards a Consumer Prices domain audience, we welcome and encourage readers from different domains to read through this report. We make significant efforts to avoid using too much domain-specific jargon, and present findings in a way that should comprehensible to a more general audience. In Chapter 10, we elaborate on aspects of our survey we believe to have high external validity, provide some practical suggestions that are applicable to Complex Analytical Systems in general, and describe some productive areas of future exploration that are not limited to the Consumer Prices business domain."
  },
  {
    "objectID": "index.html#overview-of-cpi-production-systems",
    "href": "index.html#overview-of-cpi-production-systems",
    "title": "Interim Report: Survey of CPI Production Systems",
    "section": "1.5 Overview of CPI Production Systems",
    "text": "1.5 Overview of CPI Production Systems\nWith the above motivation in mind, we conduct this survey for CPI Production Systems specifically, which are a kind of Complex Analytical System described in Section 1.3. More precisely, these systems take data on the price of consumer goods and services purchased throughout an economy and calculate period-over-period price changes of these goods and services. These price changes are ultimately mapped to a taxonomy of product categories, with the highest level of the taxonomy being the monthly “all items” CPI that is commonly used when discussing the overall level of inflation.\nThe recent adoption of alternative data sources in the calculation of CPIs has further increased the complexity of these systems,5 and has increased the importance of skills in newly emerging disciplines such as Data Science, Data Engineering, and Analytics Engineering."
  },
  {
    "objectID": "index.html#related-work",
    "href": "index.html#related-work",
    "title": "Interim Report: Survey of CPI Production Systems",
    "section": "Related Work",
    "text": "Related Work\nWe borrow and adapt several ideas presented in Skelton, Pais, and Malan (2019) such as the concepts of Stream-aligned teams and the Flow of change in our survey. These concepts (discussed in greater detail in the following sections) can be applied to understand how teams are organized around the various steps in a complex data processing workflow.\nWe also borrow a number of ideas from Forsgren, Humble, and Kim (2018). Particularly, multiple of the DevOps Research and Assessment (DORA) metrics they present are highly relevant in measuring the business outcomes of teams that maintain CPI systems6.\nWe believe that multiple ideas presented in Dehghani (2022) are highly applicable to the CPI Systems under study. Specifically, we believe that the concept of Data-as-a-Product (and teams organized around these Data Products) provides a useful framework for thinking about how these systems and teams interact with one another. We also contrast domain-oriented decentralized teams with centralized teams.\nAlthough we do not make specific references to it in our survey, we believe the Reproducible Analytical Pipeline (RAP) work by NHS (2017) does a good job at explaining how teams can introduce relevant tools and practices to workloads oriented around data processing.7\nThroughout this write up, we distinguish between software systems and IT professionals being embedded in domain teams versus being centralized outside of domain teams. Organizing software system architecture around business domains is not a new idea in software engineering (see Domain Driven Design by Evans (2004), and more recently Software Architecture: The Hard Parts by Ford et al. (2021) and Fundamentals of Software Architecture by Richards and Ford (2020), for example). However, we believe this distinction may not be well understood or formalized in the context of the teams who maintain the kinds of Complex Analytical Systems described in Section 1.2, so we pay special attention to this distinction throughout this write up."
  },
  {
    "objectID": "index.html#the-survey-process-and-aspects-of-the-collected-data",
    "href": "index.html#the-survey-process-and-aspects-of-the-collected-data",
    "title": "Interim Report: Survey of CPI Production Systems",
    "section": "The survey process and aspects of the collected data",
    "text": "The survey process and aspects of the collected data\nWe developed the survey towards the end of 2024 and ran it between January and February 2024. With support from the UN-CEBD and UNECE, we compiled and reached out to NSOs around the world. We prioritized reaching out directly to individuals in Price Statistics divisions at each NSOs, or where no contact was known, we inquired with the overall organization and requested that the survey link be forwarded to the Price Statistics team of that organization. Individuals were asked to submit one response from the organization, and where applicable, data editing was done to ensure a robust dataset was finalized.\nAround 70 NSOs responded to the survey. Every major geographic region of the world is represented in the survey. NSOs that answered included those advanced in their modernization and the use of new data sources and those that focused on traditional methods. Self-selection bias is possible (this could also be due to factors such as the time commitment necessary and the complexity of the survey). It is also possible that misinterpretation could have affected some responder answers, which we note when discussing specific topics. In summary though, despite the likelihood for self-selection bias and some misinterpretation of the questions asked, we believe the coverage is good."
  },
  {
    "objectID": "index.html#how-this-report-is-organized",
    "href": "index.html#how-this-report-is-organized",
    "title": "Interim Report: Survey of CPI Production Systems",
    "section": "1.8 How This Report Is Organized",
    "text": "1.8 How This Report Is Organized\nThis report is presented in the order that the survey was conducted, with findings presented along the way.\n\nChapter 2 covers the key conceptual models and terminology used to articulate concepts about system and team organization.\nChapter 3 analyzes our findings with respect to system and team organization.\nChapter 4 covers some high-level questions on the use of tools and technologies required to develop and maintain CPI Production Systems.\nChapter 5 covers questions about the age and update frequency of systems.\nChapter 6 covers questions about the number of individuals required to participate in system changes.\nChapter 7 covers questions about a concept called lead time, which measures the end-to-end time required to implement a change to a software component.\nChapter 8 covers questions about the usage of alternative data in CPI Production Systems.\nChapter 9 covers the challenges CPI Production System teams face with respect to maintaining their systems.\nChapter 10 concludes with a summary of the most notable findings from the survey, some practical insights to address some common areas of struggle, and some areas of future work."
  },
  {
    "objectID": "index.html#note-on-confidentiality-and-privacy",
    "href": "index.html#note-on-confidentiality-and-privacy",
    "title": "Interim Report: Survey of CPI Production Systems",
    "section": "1.9 Note on Confidentiality and Privacy",
    "text": "1.9 Note on Confidentiality and Privacy\nAs part of the administration of this survey, we ensured respondents that their data will be treated confidentiality. Therefore, no individual response data are made available in this report; all results presented are aggregated over all respondents.\n\n\n\n\nDehghani, Z. 2022. Data Mesh: Delivering Data-Driven Value at Scale. O’Reilly. https://books.google.ca/books?id=M5J5zgEACAAJ.\n\n\nEvans, E. 2004. Domain-Driven Design: Tackling Complexity in the Heart of Software. Addison-Wesley. https://books.google.ca/books?id=7dlaMs0SECsC.\n\n\nFord, N., W. M. Richards, P. J. Sadalage, and Z. Dehghani. 2021. Software Architecture: The Hard Parts : Modern Trade-Off Analysis for Distributed Architectures. O’Reilly. https://books.google.ca/books?id=sWNozgEACAAJ.\n\n\nForsgren, N., J. Humble, and G. Kim. 2018. Accelerate: The Science Behind DevOps : Building and Scaling High Performing Technology Organizations. G - Reference,information and Interdisciplinary Subjects Series. IT Revolution. https://books.google.ca/books?id=85XHAQAACAAJ.\n\n\nNHS. 2017. “Reproducible Analytical Pipelines (RAP).” https://nhsdigital.github.io/rap-community-of-practice/.\n\n\nPrice, M., and D. Marques. 2023. “Developing Reproducible Analytical Pipelines for the Transformation of Consumer Price Statistics: Rail Fares.” Office of National Statistics; \"https://unece.org/sites/default/files/2023-05/7.4%20UK_un_systems_railfares_paper.pdf\".\n\n\nRichards, M., and N. Ford. 2020. Fundamentals of Software Architecture: An Engineering Approach. O’Reilly Media, Incorporated. https://books.google.ca/books?id=_pNdwgEACAAJ.\n\n\nSkelton, M., M. Pais, and R. Malan. 2019. Team Topologies: Organizing Business and Technology Teams for Fast Flow. G - Reference,information and Interdisciplinary Subjects Series. IT Revolution. https://books.google.ca/books?id=oFdRuAEACAAJ."
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Interim Report: Survey of CPI Production Systems",
    "section": "",
    "text": "Most notable is the 2020 CPI Manual.↩︎\nSee the e-handbook, developed and maintained by the UN Task Team on Scanner data, for guidance on various aspects of leveraging new data sources.↩︎\nThe most notable approach being recommended is Reproducible Analytical Pipelines (or RAPs), which are discussed in Section 1.6. The IT system requirements section in the e-handbook also summarizes several considerations and approaches for systems development.↩︎\nWe are not implying that all “traditional” software systems have these characteristics. Rather, we are trying to draw contrast between aspects of Complex Analytical Systems that are most likely to be different from the kinds of systems a software engineer would often develop and maintain.↩︎\nIn the context of CPI Production Systems, alternative data sources refer to data such as retailer scanner and web-scraped data that can be used to calculate the component price changes that are used in CPI calculations.↩︎\nWe use slightly different terminology to refer to some of these concepts throughout the survey in order to use language that our target audience is most likely familiar with.↩︎\nFor readers who want to learn more about RAP, see this training session on RAP for price statistics by ESCAP which covers an application involving web scraping.↩︎"
  },
  {
    "objectID": "intro.html#sec-related-work",
    "href": "intro.html#sec-related-work",
    "title": "1  Introduction",
    "section": "1.4 Related Work",
    "text": "1.4 Related Work\nWe borrow and adapt several ideas presented in Skelton, Pais, and Malan (2019) such as the concepts of Stream-aligned teams and the Flow of change in our survey. These concepts (discussed in greater detail in the following sections) can be applied to understand how teams are organized around the various steps in a complex data processing workflow.\nWe also borrow a number of ideas from Forsgren, Humble, and Kim (2018). Particularly, multiple of the DevOps Research and Assessment (DORA) metrics they present are highly relevant in measuring the business outcomes of teams that maintain CPI systems6.\nWe believe that multiple ideas presented in Dehghani (2022) are highly applicable to the CPI Systems under study. Specifically, we believe that the concept of Data-as-a-Product (and teams organized around these Data Products) provides a useful framework for thinking about how these systems and teams interact with one another. We also contrast domain-oriented decentralized teams with centralized teams.\nAlthough we do not make specific references to it in our survey, we believe the Reproducible Analytical Pipeline (RAP) work by NHS (2017) does a good job at explaining how teams can introduce relevant tools and practices to workloads oriented around data processing. More information about RAP can be found on the NHS RAP Communitiy of Practice and the RAP companion website.7 Price and Marques (2023) provides a good case study on the application of RAP to production price statistics.\nThroughout this write up, we distinguish between software systems and IT professionals being embedded in domain teams versus being centralized outside of domain teams. Organizing software system architecture around business domains is not a new idea in software engineering (see Domain Driven Design by Evans (2004), and more recently Software Architecture: The Hard Parts by Ford et al. (2021) and Fundamentals of Software Architecture by Richards and Ford (2020), for example). However, we believe this distinction may not be well understood or formalized in the context of the teams who maintain the kinds of Complex Analytical Systems described in Section 1.2, so we pay special attention to this distinction throughout this write up."
  },
  {
    "objectID": "intro.html#survey-design-and-data-collection",
    "href": "intro.html#survey-design-and-data-collection",
    "title": "1  Introduction",
    "section": "1.5 Survey Design and Data Collection",
    "text": "1.5 Survey Design and Data Collection\nWe developed this survey during the fall of 2024 and administered it through the winter of 2025.\nWith support from the UN-CEBD and UNECE, we contacted NSOs around the world. We prioritized reaching out directly to individuals in the Price Statistics divisions at each NSO. Where no contact was known, we requested that the survey link be forwarded to the Price Statistics team of that organization. Each Price Statistics team submitted one response on behalf of their NSO. At the time of writing this interim report, 70 NSOs responded to our survey.\nEvery major geographic region of the world is represented in the responses. NSOs that answered ranged from those advanced in their modernization efforts to those that are still focused on traditional methods.\nWe do not make any claims about the statistical significance of results throughout this survey. Rather, the goal of this survey is to provide descriptive findings about system and team organization, and to relate these findings to prior knowledge in other disciplines such as Software Engineering.\nTo preserve anonymity, we do not disclose any values if there are 2 or fewer respondents that take on the value. As a result, throughout the report, certain tables and figures may be presented in a way where certain categories are omitted or grouped together.\nSome amount of selection bias is possible, which could be due in part to factors such as the time commitment and the complexity of the survey. It is also possible that misinterpretation could have affected some responses.\nHowever, despite these possible shortcomings, we believe the data collected is still relevant. We also believe the findings in this survey have high external validity with respect to other Complex Analytical System use cases beyond CPI production systems.\nFor readers who are interested, this survey was administered using LimeSurvey, and the questionnaire used can be found in the Github repository for this survey."
  },
  {
    "objectID": "index.html#sec-intro",
    "href": "index.html#sec-intro",
    "title": "Interim Report: Survey of CPI Production Systems",
    "section": "1.2 Overview",
    "text": "1.2 Overview\nExtensive methodological and practical guidance is available to National Statistical Organizations (NSOs) related to the creation of the Consumer Price Index (CPI).1 However, there is not much material on how to create maintainable software systems to carry out this methodological and practical guidance.\nFurthemore, many NSOs are starting to modernize their programs by shifting towards new data sources, which is similarly well supported with methodological and practical guidance.2 Again, while some resources exist,3 there is not much direction on how to deal with the complexity introduced by developing and maintaining the systems that operate on these new data sources.\nTo help mitigate this, Workstream 4 of the UN Task Team on Scanner data conducted a detailed survey during the winter of 2025 to (1) provide a detailed summary of the CPI production systems currently used by NSOs and (2) provide guidance in the form of this report on how NSOs can better manage the complexities of system development and maintenance.\nWhile this report is specific to the state of CPI Production Systems at NSOs around the world, our hope is that some of the content in this report is also useful for a wider audience maintaining similar kinds of systems. As such, we attempt to explain our results in a general way and highlight opportunities where our survey approach and findings could be applied in related settings."
  },
  {
    "objectID": "index.html#sec-related-work",
    "href": "index.html#sec-related-work",
    "title": "Interim Report: Survey of CPI Production Systems",
    "section": "1.6 Related Work",
    "text": "1.6 Related Work\nWe borrow and adapt several ideas presented in Skelton, Pais, and Malan (2019) such as the concepts of Stream-aligned teams and the Flow of change in our survey. These concepts (discussed in greater detail in the following sections) can be applied to understand how teams are organized around the various steps in a complex data processing workflow.\nWe also borrow a number of ideas from Forsgren, Humble, and Kim (2018). Particularly, multiple of the DevOps Research and Assessment (DORA) metrics they present are highly relevant in measuring the business outcomes of teams that maintain CPI systems6.\nWe believe that multiple ideas presented in Dehghani (2022) are highly applicable to the CPI Systems under study. Specifically, we believe that the concept of Data-as-a-Product (and teams organized around these Data Products) provides a useful framework for thinking about how these systems and teams interact with one another. We also contrast domain-oriented decentralized teams with centralized teams.\nAlthough we do not make specific references to it in our survey, we believe the Reproducible Analytical Pipeline (RAP) work by NHS (2017) does a good job at explaining how teams can introduce relevant tools and practices to workloads oriented around data processing. More information about RAP can be found on the NHS RAP Communitiy of Practice and the RAP companion website.7 Price and Marques (2023) provides a good case study on the application of RAP to production price statistics.\nThroughout this write up, we distinguish between software systems and IT professionals being embedded in domain teams versus being centralized outside of domain teams. Organizing software system architecture around business domains is not a new idea in software engineering (see Domain Driven Design by Evans (2004), and more recently Software Architecture: The Hard Parts by Ford et al. (2021) and Fundamentals of Software Architecture by Richards and Ford (2020), for example). However, we believe this distinction may not be well understood or formalized in the context of the teams who maintain the kinds of Complex Analytical Systems described in Section 1.4, so we pay special attention to this distinction throughout this write up."
  },
  {
    "objectID": "index.html#survey-design-and-data-collection",
    "href": "index.html#survey-design-and-data-collection",
    "title": "Interim Report: Survey of CPI Production Systems",
    "section": "1.7 Survey Design and Data Collection",
    "text": "1.7 Survey Design and Data Collection\nWe developed this survey during the fall of 2024 and administered it through the winter of 2025.\nWith support from the UN-CEBD and UNECE, we contacted NSOs around the world. We prioritized reaching out directly to individuals in the Price Statistics divisions at each NSO. Where no contact was known, we requested that the survey link be forwarded to the Price Statistics team of that organization. Each Price Statistics team submitted one response on behalf of their NSO. At the time of writing this interim report, 70 NSOs responded to our survey.\nEvery major geographic region of the world is represented in the responses. NSOs that answered ranged from those advanced in their modernization efforts to those that are still focused on traditional methods.\nWe do not make any claims about the statistical significance of results throughout this survey. Rather, the goal of this survey is to provide descriptive findings about system and team organization, and to relate these findings to prior knowledge in other disciplines such as Software Engineering.\nTo preserve anonymity, we do not disclose any values if there are 2 or fewer respondents that take on the value. As a result, throughout the report, certain tables and figures may be presented in a way where certain categories are omitted or grouped together.\nSome amount of selection bias is possible, which could be in part due to factors such as the time commitment and the complexity of the survey. It is also possible that misinterpretation could have affected some responses.\nHowever, despite these possible shortcomings, we believe the data collected are still relevant. We also believe that the findings in this survey have high external validity with respect to other Complex Analytical Systems beyond CPI production systems.\nFor readers who are interested, this survey was administered using LimeSurvey, and the questionnaire used can be found in the Github repository for this survey."
  },
  {
    "objectID": "findings-and-next-steps.html#data-availability",
    "href": "findings-and-next-steps.html#data-availability",
    "title": "10  Conclusion",
    "section": "10.4 Data Availability",
    "text": "10.4 Data Availability\nAs of this interim report, the data used are not publicly available. If a sufficient number of respondents provide consent to share their anonymized responses, we will release an anonymized version of the survey dataset into the public domain."
  },
  {
    "objectID": "findings-and-next-steps.html#code-availability",
    "href": "findings-and-next-steps.html#code-availability",
    "title": "10  Conclusion",
    "section": "10.5 Code Availability",
    "text": "10.5 Code Availability\nThis report was created using Quarto. All figures and tables used throughout the report are rendered in-place when the report is created. All of the source content for this report is available in our GitHub repository."
  },
  {
    "objectID": "findings-and-next-steps.html#acknowledgements",
    "href": "findings-and-next-steps.html#acknowledgements",
    "title": "10  Conclusion",
    "section": "10.6 Acknowledgements",
    "text": "10.6 Acknowledgements\nWe reiterate our appreciation and acknoledgements mentioned in Section 1.1 to the various UN groups who supported this work. Without their support and guidance, administering this survey would not have been possible.\n\n\n\n\nForsgren, N., J. Humble, and G. Kim. 2018. Accelerate: The Science Behind DevOps : Building and Scaling High Performing Technology Organizations. G - Reference,information and Interdisciplinary Subjects Series. IT Revolution. https://books.google.ca/books?id=85XHAQAACAAJ.\n\n\nNHS. 2017. “Reproducible Analytical Pipelines (RAP).” https://nhsdigital.github.io/rap-community-of-practice/."
  },
  {
    "objectID": "findings-and-next-steps.html#author-information",
    "href": "findings-and-next-steps.html#author-information",
    "title": "10  Conclusion",
    "section": "10.7 Author Information",
    "text": "10.7 Author Information\n\nCollin Brown, Statistics Canada\nSteve Martin, Statistics Canada\n\n\n\n\n\nForsgren, N., J. Humble, and G. Kim. 2018. Accelerate: The Science Behind DevOps : Building and Scaling High Performing Technology Organizations. G - Reference,information and Interdisciplinary Subjects Series. IT Revolution. https://books.google.ca/books?id=85XHAQAACAAJ.\n\n\nNHS. 2017. “Reproducible Analytical Pipelines (RAP).” https://nhsdigital.github.io/rap-community-of-practice/."
  },
  {
    "objectID": "index.html#sec-preface",
    "href": "index.html#sec-preface",
    "title": "Interim Report: Survey of CPI Production Systems",
    "section": "1.1 Preface",
    "text": "1.1 Preface\nThis work showcases the findings and takeaways from surveying National Statistical Organizations (NSOs) around the world during the winter of 2025. The survey primarily focused on how each NSO structures, develops, and maintains their Consumer Price Index (CPI) production systems and organizes the teams that are responsible for these systems.\n\n\n\nThis work was done by Workstream 4 (CPI Systems and Architecture), which is part of the UN Task Team on Scanner Data. Hence, we would like to acknowledge the team members of Workstream 4 who provided insights, helped draft survey questions, and supported this empirical assessment.\n\n\n\n\n\n\nWe would also like to thank and acknowledge the support of the Steering Group of the UN Task Team on Scanner Data, as well as the UN Committee of Experts on Big Data and Data Science for Official Statistics (UN-CEBD) team in making this work possible. Without the support of both, it would not have been possible to survey NSOs around the world and evaluate their CPI production system architectures and team organizations."
  }
]