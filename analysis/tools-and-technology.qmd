# Tools and Technologies {#sec-tools-tech}

In this section, we look at various tools and technologies in use by NSOs.

## Version Control System Usage {#sec-vcs}

Complex Analytical Systems, such as the systems used in monthly CPI Production, often need to synchronize and integrate multiple versions of related code, data, and documentation. This is especially important for creating reproducible analytical pipelines (@RAPsite), or enabling multiple individuals to work concurrently on the same project.

Version Control Systems (VCS) are tools that systematically manage changes in a codebase over time. At the time of writing, [Git](https://git-scm.com/) is by far the most popular software for this purpose, and platforms such as [Github](https://github.com/) and [GitLab](https://about.gitlab.com/) have built extensive functionality around projects managed with Git[^tools-and-technology-1].

[^tools-and-technology-1]: It is worth mentioning that git-adjacent software such as [Data Version Control](https://dvc.org/) and [Git Large File Storage](https://git-lfs.com/) exists to extend the versioning capabilities of Git to files you wouldn't typically commit to a Git repository. However, this is a more advanced topic that we did not investigate in this survey.

```{r message = FALSE}
#| echo: false
#| label: fig-comm-software
#| fig-cap: VCS used by survey respondents

library(dplyr)
library(ggplot2)

df <- read.csv("./data/results.csv")
df <- df[df[,2] != "",]

# Filter and rename columns used in the analysis for this page
df <- df |> rename(
  sg1_ing=colnames(df)[67],
  sg1_proc=colnames(df)[68],
  sg1_elem=colnames(df)[69],
  sg1_agg=colnames(df)[70],
  sg1_fin=colnames(df)[71],
  sg2_ing=colnames(df)[72],
  sg2_proc=colnames(df)[73],
  sg2_elem=colnames(df)[74],
  sg2_agg=colnames(df)[75],
  sg2_fin=colnames(df)[76],
  sg3_ing=colnames(df)[77],
  sg3_proc=colnames(df)[78],
  sg3_elem=colnames(df)[79],
  sg3_agg=colnames(df)[80],
  sg3_fin=colnames(df)[81],
  sg4_ing=colnames(df)[82],
  sg4_proc=colnames(df)[83],
  sg4_elem=colnames(df)[84],
  sg4_agg=colnames(df)[85],
  sg4_fin=colnames(df)[86],
  sg5_ing=colnames(df)[87],
  sg5_proc=colnames(df)[88],
  sg5_elem=colnames(df)[89],
  sg5_agg=colnames(df)[90],
  sg5_fin=colnames(df)[91],
  sg1_cit=colnames(df)[92],
  sg1_dit=colnames(df)[93],
  sg1_dan=colnames(df)[94],
  sg1_ean=colnames(df)[95],
  sg1_con=colnames(df)[96],
  sg2_cit=colnames(df)[97],
  sg2_dit=colnames(df)[98],
  sg2_dan=colnames(df)[99],
  sg2_ean=colnames(df)[100],
  sg2_con=colnames(df)[101],
  sg3_cit=colnames(df)[102],
  sg3_dit=colnames(df)[103],
  sg3_dan=colnames(df)[104],
  sg3_ean=colnames(df)[105],
  sg3_con=colnames(df)[106],
  sg4_cit=colnames(df)[107],
  sg4_dit=colnames(df)[108],
  sg4_dan=colnames(df)[109],
  sg4_ean=colnames(df)[110],
  sg4_con=colnames(df)[111],
  sg5_cit=colnames(df)[112],
  sg5_dit=colnames(df)[113],
  sg5_dan=colnames(df)[114],
  sg5_ean=colnames(df)[115],
  sg5_con=colnames(df)[116],
)
# df <- df[,67:116]

# Fill NA values with zero
# df[,67:116] <- 0

systems_matrix <- function(row) {
  q1 <- matrix(nrow=5, ncol=5)
  q1[1,] <- as.numeric(obs[,67:71])
  q1[2,] <- as.numeric(obs[,72:76])
  q1[3,] <- as.numeric(obs[,77:81])
  q1[4,] <- as.numeric(obs[,82:86])
  q1[5,] <- as.numeric(obs[,87:91])
  
  q1[is.na(q1)] = 0
  
  q1
}

maintainer_matrix <- function(row) {
  q2 <- matrix(nrow=5, ncol=5)
  q2[1,] <- as.numeric(obs[,92:96])
  q2[2,] <- as.numeric(obs[,97:101])
  q2[3,] <- as.numeric(obs[,102:106])
  q2[4,] <- as.numeric(obs[,107:111])
  q2[5,] <- as.numeric(obs[,112:116])
  
  q2[is.na(q2)] = 0
  
  q2
}

similarity_metric <- function(a, b) {
  num <- sum(a == TRUE & b == TRUE)
  denom <- sum(b == TRUE)
  num / denom
}

# ---------------------
# Add a column to indicate whether the organization has a monolith
# ---------------------

df$has_monolith = FALSE

for (i in 1:nrow(df)) {
  obs <- df[i,]
  # Get matrix of system groups and maintainers
  sys_grps <- systems_matrix(obs)
  maintainers <- maintainer_matrix(obs)
  # Define the monolith condition (i.e, there is only one system group that does
  # every GSBPM step).
  cit_idx <- all(as.logical(sys_grps[1,1:5])) |
             all(as.logical(sys_grps[2,1:5])) |
             all(as.logical(sys_grps[3,1:5])) |
             all(as.logical(sys_grps[4,1:5])) |
             all(as.logical(sys_grps[5,1:5])) 
  # If any system group is a monolith, add these counts to cumulative links and flag
  # this row as an organization that has at least one monolith.
  if (cit_idx & df[i, 15] != "No") {
    df[i, "has_monolith"] = TRUE
  }
}


# ---------------------
# Add a column to indicate whether the organization has a hybrid architecture
# ---------------------

df$has_hybrid_arch = FALSE

for (i in 1:nrow(df)) {
  obs <- df[i,]
  # Get matrix of system groups and maintainers
  sys_grps <- systems_matrix(obs)
  maintainers <- maintainer_matrix(obs)
  # Define the hybrid architecture condition (at least one GSBPM step defined in groups 1 and 2, all else zero)
  cit_idx <- (sys_grps[1,1] == 1 | sys_grps[1,2] == 1 | sys_grps[1,3] == 1 | sys_grps[1,4] == 1 | sys_grps[1,5] == 1) &
             (sys_grps[2,1] == 1 | sys_grps[2,2] == 1 | sys_grps[2,3] == 1 | sys_grps[2,4] == 1 | sys_grps[2,5] == 1) &
              all(sys_grps[3:5, 1:5] == 0)
  # If there are two system groups **and** these groups are not monoliths, then
  # we consider these to be hybrid systems. The rationale here is that if a representative
  # system has 2 system groups and each system group is a monolith, then this isn't really
  # a hybrid system with a "boundary" between two groups.
  if (cit_idx & !df[i, "has_monolith"]) {
    df[i, "has_hybrid_arch"] = TRUE
  }
}

# ---------------------
# Add a column to indicate whether the organization has a "modular" architecture
# ---------------------

df$has_modular = FALSE

for (i in 1:nrow(df)) {
  obs <- df[i,]
  # Get matrix of system groups and maintainers
  sys_grps <- systems_matrix(obs)
  maintainers <- maintainer_matrix(obs)
  # Define the modular architecture
  cit_idx <- (sys_grps[1,1] == 1 | sys_grps[1,2] == 1 | sys_grps[1,3] == 1 | sys_grps[1,4] == 1 | sys_grps[1,5] == 1) &
             (sys_grps[2,1] == 1 | sys_grps[2,2] == 1 | sys_grps[2,3] == 1 | sys_grps[2,4] == 1 | sys_grps[2,5] == 1) &
             (sys_grps[2,1] == 1 | sys_grps[2,2] == 1 | sys_grps[2,3] == 1 | sys_grps[2,4] == 1 | sys_grps[2,5] == 1)
  if (cit_idx & !df[i, "has_monolith"] & !df[i, "has_hybrid_arch"]) {
    df[i, "has_modular"] = TRUE
  }
}

# Any organization that doesn't fit one of the 3 definitions above is excluded
# because the answers are incomplete. Drop these records from the analysis
df <- df[df$has_monolith | df$has_hybrid_arch | df$has_modular, ]

# ---------------------
# Add a column to indicate whether the organization has stream aligned teams
# maintaining the representative system
# ---------------------

df$has_stream_aligned_team = FALSE

# This is the order of the maintainer columns
# c("Corporate IT", "Domain-Embedded IT", "Domain-Embedded Analysts", "Elsewhere Analysts", "Consultants")

for (i in 1:nrow(df)) {
  obs <- df[i,]
  # Get matrix of system groups and maintainers
  sys_grps <- systems_matrix(obs)
  maintainers <- maintainer_matrix(obs)
  # Define the stream aligned team condition as one or more maintainer groups being comprised of either
  # domain-analysts only, domain-IT only, or both domain analysts and domain IT (but no other groups).
  idx <- (maintainers[1,1] == 0 & maintainers[1,4] == 0 & maintainers[1,5] == 0) & (maintainers[1,2] == 1 | maintainers[1,3] == 1) |
         (maintainers[2,1] == 0 & maintainers[2,4] == 0 & maintainers[2,5] == 0) & (maintainers[2,2] == 1 | maintainers[2,3] == 1) |
         (maintainers[3,1] == 0 & maintainers[3,4] == 0 & maintainers[3,5] == 0) & (maintainers[3,2] == 1 | maintainers[3,3] == 1) |
         (maintainers[4,1] == 0 & maintainers[4,4] == 0 & maintainers[4,5] == 0) & (maintainers[4,2] == 1 | maintainers[4,3] == 1) |
         (maintainers[5,1] == 0 & maintainers[5,4] == 0 & maintainers[5,5] == 0) & (maintainers[5,2] == 1 | maintainers[5,3] == 1)
  if (idx) {
    df[i, "has_stream_aligned_team"] = TRUE
  }
}

# ---------------------
# Add a column to indicate whether the organization has IT-only teams maintaining
# any of its representative systems
# ---------------------

df$has_it_only_team = FALSE

# This is the order of the maintainer columns
# c("Corporate IT", "Domain-Embedded IT", "Domain-Embedded Analysts", "Elsewhere Analysts", "Consultants")

for (i in 1:nrow(df)) {
  obs <- df[i,]
  # Get matrix of system groups and maintainers
  sys_grps <- systems_matrix(obs)
  maintainers <- maintainer_matrix(obs)
  # Define the stream aligned team condition as one or more maintainer groups being comprised of either
  # domain-analysts only, domain-IT only, or both domain analysts and domain IT (but no other groups).
  idx <- (maintainers[1,3] == 0 & maintainers[1,4] == 0 & maintainers[1,5] == 0) & (maintainers[1,2] == 1 | maintainers[1,1] == 1) |
         (maintainers[2,3] == 0 & maintainers[2,4] == 0 & maintainers[2,5] == 0) & (maintainers[2,2] == 1 | maintainers[2,1] == 1) |
         (maintainers[3,3] == 0 & maintainers[3,4] == 0 & maintainers[3,5] == 0) & (maintainers[3,2] == 1 | maintainers[3,1] == 1) |
         (maintainers[4,3] == 0 & maintainers[4,4] == 0 & maintainers[4,5] == 0) & (maintainers[4,2] == 1 | maintainers[4,1] == 1) |
         (maintainers[5,3] == 0 & maintainers[5,4] == 0 & maintainers[5,5] == 0) & (maintainers[5,2] == 1 | maintainers[5,1] == 1)
  if (idx) {
    df[i, "has_it_only_team"] = TRUE
  }
}

# ---------------------
# Add a column to indicate whether the organization has analyst-only teams maintaining
# any of its representative systems
# ---------------------

df$has_analyst_only_team = FALSE

# This is the order of the maintainer columns
# c("Corporate IT", "Domain-Embedded IT", "Domain-Embedded Analysts", "Elsewhere Analysts", "Consultants")

for (i in 1:nrow(df)) {
  obs <- df[i,]
  # Get matrix of system groups and maintainers
  sys_grps <- systems_matrix(obs)
  maintainers <- maintainer_matrix(obs)
  # Define the stream aligned team condition as one or more maintainer groups being comprised of either
  # domain-analysts only, domain-IT only, or both domain analysts and domain IT (but no other groups).
  idx <- (maintainers[1,1] == 0 & maintainers[1,2] == 0 & maintainers[1,5] == 0) & (maintainers[1,3] == 1 | maintainers[1,4] == 1) |
         (maintainers[2,1] == 0 & maintainers[2,2] == 0 & maintainers[2,5] == 0) & (maintainers[2,3] == 1 | maintainers[2,4] == 1) |
         (maintainers[3,1] == 0 & maintainers[3,2] == 0 & maintainers[3,5] == 0) & (maintainers[3,3] == 1 | maintainers[3,4] == 1) |
         (maintainers[4,1] == 0 & maintainers[4,2] == 0 & maintainers[4,5] == 0) & (maintainers[4,3] == 1 | maintainers[4,4] == 1) |
         (maintainers[5,1] == 0 & maintainers[5,2] == 0 & maintainers[5,5] == 0) & (maintainers[5,3] == 1 | maintainers[5,4] == 1)
  if (idx) {
    df[i, "has_analyst_only_team"] = TRUE
  }
}

# ---------------------
# Add a column to indicate whether the organization has "other" teams maintaining
# any of its representative systems
# ---------------------

df$has_other_mix_team = FALSE

# This is the order of the maintainer columns
# c("Corporate IT", "Domain-Embedded IT", "Domain-Embedded Analysts", "Elsewhere Analysts", "Consultants")

for (i in 1:nrow(df)) {
  obs <- df[i,]
  # Get matrix of system groups and maintainers
  sys_grps <- systems_matrix(obs)
  maintainers <- maintainer_matrix(obs)
  # An "Other" mix is anything that's not stream aligned, IT-only, or analyst-only.
  # Any organization that doesn't have any of the other team types is "other".
  if (!df[i, "has_stream_aligned_team"] & !df[i, "has_it_only_team"] & !df[i, "has_analyst_only_team"]) {
    df[i, "has_other_mix_team"] = TRUE
  }
}

team_arch_mat <- matrix(nrow=5, ncol=3)

# mono-stream
team_arch_mat[1,1] <- similarity_metric(df$has_monolith, df$has_stream_aligned_team)
# mono-it-only
team_arch_mat[2,1] <- similarity_metric(df$has_monolith, df$has_it_only_team)
# mono-analyst-only
team_arch_mat[3,1] <- similarity_metric(df$has_monolith, df$has_analyst_only_team)
# Other mix teams
team_arch_mat[4,1] <- similarity_metric(df$has_monolith, df$has_other_mix_team)
# Sample average (i.e., all teams)
team_arch_mat[5,1] <- similarity_metric(df$has_monolith, rep(TRUE, nrow(df)))

# hybrid-stream
team_arch_mat[1,2] <- similarity_metric(df$has_hybrid_arch, df$has_stream_aligned_team)
# hybrid-it-only
team_arch_mat[2,2] <- similarity_metric(df$has_hybrid_arch, df$has_it_only_team)
# hybrid-analyst-only
team_arch_mat[3,2] <- similarity_metric(df$has_hybrid_arch, df$has_analyst_only_team)
# Other mix teams
team_arch_mat[4,2] <- similarity_metric(df$has_hybrid_arch, df$has_other_mix_team)
# Sample average (i.e., all teams)
team_arch_mat[5,2] <- similarity_metric(df$has_hybrid_arch, rep(TRUE, nrow(df)))

# modular-stream
team_arch_mat[1,3] <- similarity_metric(df$has_modular, df$has_stream_aligned_team)
# modular-it-only
team_arch_mat[2,3] <- similarity_metric(df$has_modular, df$has_it_only_team)
# modular-analyst-only
team_arch_mat[3,3] <- similarity_metric(df$has_modular, df$has_analyst_only_team)
# Other mix teams
team_arch_mat[4,3] <- similarity_metric(df$has_modular, df$has_other_mix_team)
# Sample average (i.e., all teams)
team_arch_mat[5,3] <- similarity_metric(df$has_modular, rep(TRUE, nrow(df)))


rownames(team_arch_mat) <- c("Stream Aligned Team", "IT-Only Team", "Analyst-Only Team", "Other Mix", "Sample Average")
colnames(team_arch_mat) <- c("Monolith", "Hybrid", "Modular")

# Define separate dfs for each architecture type and team type
monolith_df = df[df$has_monolith,]
hybrid_df = df[df$has_hybrid_arch,]
modular_df = df[df$has_modular,]

stream_aligned_df = df[df$has_stream_aligned_team,]
it_only_df = df[df$has_it_only_team,]
analyst_only_df = df[df$has_analyst_only_team,]
other_mix_df = df[df$has_other_mix_team,]

df <- df |> rename(
  use_open_source_pkg=colnames(df)[118],
  not_use_not_know=colnames(df)[120],
  not_use_insuff_doc=colnames(df)[121],
  not_use_code_not_maintain=colnames(df)[122],
  not_use_not_suitable=colnames(df)[123],
  not_use_not_integrate=colnames(df)[124],
  not_use_no_skills=colnames(df)[125],
  not_use_other=colnames(df)[126],
  vc_git=colnames(df)[137],
  vc_github=colnames(df)[138],
  vc_svn=colnames(df)[139],
  vc_hg=colnames(df)[140],
  vc_commercial=colnames(df)[141],
  vc_naming_convention=colnames(df)[142],
  vc_none=colnames(df)[143],
  vc_other=colnames(df)[144],
  pm_jira=colnames(df)[145],
  pm_gh_proj=colnames(df)[146],
  pm_gitlab_issue=colnames(df)[147],
  pm_share_excel=colnames(df)[148],
  pm_none=colnames(df)[149],
  pm_other=colnames(df)[150],
  cs_warehouse=colnames(df)[173],
  cs_sas=colnames(df)[174],
  cs_stata=colnames(df)[175],
  cs_matlab=colnames(df)[176],
  cs_spss=colnames(df)[177],
  cs_excel=colnames(df)[178],
  cs_pbi=colnames(df)[179],
  cs_access=colnames(df)[180],
  cs_none=colnames(df)[181],
  cs_other=colnames(df)[182]
)

# Version control
dat <- data.frame(
  Frequency = c(df$vc_git, df$vc_github, df$vc_commercial, df$vc_naming_convention, df$vc_none),
  VCS = c(
    rep("Git", each=nrow(df)),
    rep("GitHub/GitLab", each=nrow(df)),
    rep("Built-In Versioning", each=nrow(df)),
    rep("File Naming Conventions", each=nrow(df)),
    rep("None", each=nrow(df))
  )
)

# Fill NA with zero
dat$Frequency = ifelse(dat$Frequency == "Yes", 1, 0)
ggplot(dat, aes(x=VCS, y=Frequency)) + geom_bar(stat="identity", fill="#F1502F") + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + labs(title="Version Control Systems Used")

NUM_NONE_OR_FILE_NAMING_CONVENTION = sum(df$vc_none == "Yes" | df$vc_naming_convention == "Yes")

GIT_OR_GITHUB = sum(df$vc_git == "Yes" | df$vc_github == "Yes")

```

@fig-vcs shows the VCS used by respondent NSOs.

Surprisingly, the most common response by far was that the respondent did not use version control software at all for their CPI Production Systems. In fact, almost two thirds of the sample claims to use no VCS whatsoever or file-naming conventions[^tools-and-technology-2].

[^tools-and-technology-2]: What we mean by file naming conventions is encoding the author, version, and date information into the names of multiple files as the primary system of revision control. E.g., `analysis_collin_v1.py`, `analysis_steve_v2.py`, `analysis_collin_v2_final_2025_03.py`, `analysis_steve_v2_final_FINAL_2025_04.py`, and so on.

Our hypothesis here is that (1) some commonly used file formats (e.g., Excel Workbooks) don't lend themselves easily to well-established version control tools like Git and (2) a lack of familiarity with VCS tools in general.

Another interesting observation is that slightly less than one third of the sample uses Git and/or GitHub/GitLab[^tools-and-technology-3].

[^tools-and-technology-3]: We were surprised to find a small number of respondents indicated that they use Git but not a developer platform built around Git such as GitHub, GitLab, or BitBucket. We suspect that these individuals may work in an air-gapped network or similar situation without internet access and use Git locally without also using a tool like GitLab/GitHub.

A very small fraction of the sample indicated using other version control software such as Mercurial, Subversion, or built-in versioning capabilities of another tool/platform.

We echo the recommendations of [RAP](https://nhsdigital.github.io/rap-community-of-practice/introduction_to_RAP/what_is_RAP/#version-control) and [the Turing way](https://book.the-turing-way.org/reproducible-research/vcs/vcs-workflow) to strongly recommend adopting industry standard VCS. It may greatly reduce the cognitive load for teams who are not currently using any VCS or are only using file-naming conventions to manage source code and documentation for Complex Analytical Systems[^tools-and-technology-4].

[^tools-and-technology-4]: We believe that most people working on CPI Production Systems have the aptitude to learn Git. However, we acknowledge that the learning curve for Git is non-trivial. Our recommendation to readers who are interested is to [learn the basics](https://git-scm.com/book/en/v2/Git-Basics-Getting-a-Git-Repository) and immediately put this knowledge into practice in your day-to-day activities. Over time, versioning files with Git will become second nature.

## Commercial Software

The next question we asked was which commercial software (if any) is used in each respondent's CPI Production systems.

```{r}
#| echo: false
#| label: fig-commercial-software
#| fig-cap: Commercial software used by survey respondents


# Version control
dat <- data.frame(
  Frequency = c(df$cs_warehouse, df$cs_sas, df$cs_excel, df$cs_pbi, df$cs_access, df$cs_none),
  Software = c(
    rep("Data Warehouse", each=nrow(df)),
    rep("SAS", each=nrow(df)),
    rep("Excel", each=nrow(df)),
    rep("Power BI", each=nrow(df)),
    rep("MS Access", each=nrow(df)),
    rep("None", each=nrow(df))
  )
)

# Fill NA with zero
dat$Frequency = ifelse(dat$Frequency == "Yes", 1, 0)
ggplot(dat, aes(x=Software, y=Frequency)) + geom_bar(stat="identity", fill="#1d6f42") + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + labs(title="Commercial Software Used")
```

Over two thirds of the respondents listed that Microsoft Excel was used in their CPI Production Systems.

Microsoft Excel satisfies a number of use cases for basic tabular data analysis, however, it is not an ideal tool for expressing business logic in Complex Analytical Systems[^tools-and-technology-5]. Some of the key reasons for this include:

[^tools-and-technology-5]: Our criticism here applies to **all spreadsheet software**, not just Microsoft Excel. Our point is that spreadsheet workbooks are not an ideal unit of software for expressing business logic in Complex Analytical Systems.

-   Excel Workbooks are stored in a binary format rather than a plain text format, which doesn't integrate well with Version Control Systems.

-   There isn't a well-defined entrypoint to an Excel Workbook (i.e., you can't "run" an Excel workbook the same way you can "run" `python main.py`).

-   The business logic encoded into an Excel Workbook is often difficult to read and interpret for any non-trivial Workbook, making Excel Workbooks difficult to maintain as a unit of software.

-   Excel Workbooks encourage a high degree of coupling between business logic and data[^tools-and-technology-6].

[^tools-and-technology-6]: In other words, you can't easily "reuse" a piece of business logic from someone else's Excel Workbook in the way that you can reuse a piece of source code.

In a distant second to Microsoft Excel, we find SAS is the next most commonly used commercial product in CPI Production Systems.

## Project Management Software

We asked respondents which project management software they use to manage work done on their CPI Production Systems.

The exact set of features provided by project management software differ depending on the specific software used, but in general, this kind of software is used to plan and coordinate tasks, manage timelines, and track progress on work items. Given the complexity of the CPI and many factors that need to be coordinated and tracked for each change, project management software has a major productivity impact on users.

We believe that using some purpose-built project management software for any non-trivial project is generally a good idea because it encourages a structure to the way projects are managed and it offers a way to reduce cognitive burden for project team members[^tools-and-technology-7].

[^tools-and-technology-7]: Note that we are not advocating for any specific project management software product. Rather, we are encouraging the use of any purpose-built project management software to facilitate managing non-trivial projects.

```{r}
#| echo: false

# Project Management
dat <- data.frame(
  Frequency = c(df$pm_jira, df$pm_gitlab_issue, df$pm_share_excel, df$pm_none),
  Software = c(
    rep("Jira", each=nrow(df)),
    rep("GitLab Milestones", each=nrow(df)),
    rep("Shared Excel Workbook", each=nrow(df)),
    rep("None", each=nrow(df))
  )
)

# Fill NA with zero
dat$Frequency = ifelse(dat$Frequency == "Yes", 1, 0)
ggplot(dat, aes(x=Software, y=Frequency)) + geom_bar(stat="identity", fill="#0052CC") + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + labs(title="Project Management Software Used")
```

```{r}
#| echo: false

NUM_EXCEL_WB = sum(df$pm_share_excel == "Yes")
NUM_NONE = sum(df$pm_none == "Yes")
NUM_SOMETHING_ELSE = sum(df$pm_gh_proj == "Yes" | df$pm_gitlab_issue == "Yes" | df$pm_jira == "Yes" | df$pm_other == "Yes")
```

The most common project management software reported was a shared Excel Workbook, with a bit less than half of respondents stating that they used this as their team's primary means of project management.

Shared Excel Workbooks may be sufficient for keeping track of small tasks, but for any endeavour that requires managing code, data, and documentation changes across multiple individuals, this approach will lack a number of key features to facilitate the project management process.

The second most cited answer was not using any project management software whatsoever, with almost one third of respondents indicating this answer.

Given the complexity of CPI Production Systems, we were surprised to see so many individuals not using any project management software. For all but the simplest of initiatives, we believe there is significant value in adopting at least the basic features of some purpose-built project management software[^tools-and-technology-8].

[^tools-and-technology-8]: By "basic features", we're referring to capabilities such as task tracking, milestone tracking, and the ability to see which tasks each colleague is working on at any given time.

Finally, just over twenty percent of the sample reported using either GitHub Projects, GitLab Milestones, or Jira as their primary software for project management.

## Programming Languages

We asked respondents which programming languages are used to develop their CPI Production Systems. We found several observations noteworthy.

```{r message = FALSE}
#| echo: false

library(dplyr)
library(ggplot2)

# df <- read.csv("./data/results.csv")
# df <- df[df[,2] != "",]

df <- df |> rename(
  python=colnames(df)[151],
  r=colnames(df)[152],
  julia=colnames(df)[153],
  scala=colnames(df)[154],
  java=colnames(df)[155],
  csharp=colnames(df)[156],
  corcpp=colnames(df)[157],
  vb=colnames(df)[158],
  vba=colnames(df)[159],
  sas=colnames(df)[160],
  stata=colnames(df)[161],
  spss=colnames(df)[162],
  sql=colnames(df)[163],
  none=colnames(df)[164],
  other=colnames(df)[165]
)

modular_df <- modular_df |> rename(
  python=colnames(modular_df)[151],
  r=colnames(modular_df)[152],
  julia=colnames(modular_df)[153],
  scala=colnames(modular_df)[154],
  java=colnames(modular_df)[155],
  csharp=colnames(modular_df)[156],
  corcpp=colnames(modular_df)[157],
  vb=colnames(modular_df)[158],
  vba=colnames(modular_df)[159],
  sas=colnames(modular_df)[160],
  stata=colnames(modular_df)[161],
  spss=colnames(modular_df)[162],
  sql=colnames(modular_df)[163],
  none=colnames(modular_df)[164],
  other=colnames(modular_df)[165]
)

monolith_df <- monolith_df |> rename(
  python=colnames(monolith_df)[151],
  r=colnames(monolith_df)[152],
  julia=colnames(monolith_df)[153],
  scala=colnames(monolith_df)[154],
  java=colnames(monolith_df)[155],
  csharp=colnames(monolith_df)[156],
  corcpp=colnames(monolith_df)[157],
  vb=colnames(monolith_df)[158],
  vba=colnames(monolith_df)[159],
  sas=colnames(monolith_df)[160],
  stata=colnames(monolith_df)[161],
  spss=colnames(monolith_df)[162],
  sql=colnames(monolith_df)[163],
  none=colnames(monolith_df)[164],
  other=colnames(monolith_df)[165]
)

# Version control
dat <- data.frame(
  Frequency = c(
    df$python,
    df$r,
    df$java,
    df$csharp,
    df$corcpp,
    df$vb,
    df$vba,
    df$sas,
    df$sql,
    df$none
  ),
  Language = c(
    rep("Python", each=nrow(df)),
    rep("R", each=nrow(df)),
    rep("Java", each=nrow(df)),
    rep("C#", each=nrow(df)),
    rep("C/C++", each=nrow(df)),
    rep("Visual Basic", each=nrow(df)),
    rep("Visual Basic Applications", each=nrow(df)),
    rep("SAS", each=nrow(df)),
    rep("SQL", each=nrow(df)),
    rep("None", each=nrow(df))
  )
)

# Fill NA with zero
dat$Frequency = ifelse(dat$Frequency == "Yes", 1, 0)
ggplot(dat, aes(x=Language, y=Frequency)) + geom_bar(stat="identity", fill="#FFE873") + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + labs(title="Programming Languages Used")
```

```{r}
#| echo: false

NUM_SQL = sum(df$sql == "Yes")

PYTHON_OR_R_OR_SAS = sum(df$python == "Yes" | df$r == "Yes" | df$sas == "No")
PYTHON_OR_R_NOT_SAS = sum((df$python == "Yes" | df$r == "Yes") & df$sas == "No")

NONE_LANGUAGE = sum(df$none == "Yes")
```

First, just under half of the respondents indicated that they use SQL in the development of their CPI Production Systems.

We suspect this answer reflects the fact that SQL still remains a very popular choice of language for expressing tabular data manipulations, as well as the fact that many organizations reported using some kind of database management system (DBMS) in their CPI Production Systems. Our suspicion is that SQL is most commonly used in the ingestion and processing steps in the flow of change[^tools-and-technology-9].

[^tools-and-technology-9]: To minimize response burden, we did not ask respondents to enumerate programming languages used by GSBPM step, so we cannot say for sure in which step(s) SQL is used.

Second, we notice than more than ninety percent of the sample reported using **at least one of** Python, R, and SAS in their CPI Production Systems. Interestingly, less than one quarter of these users reported using Python and/or R but not SAS. In other words, it is quite common for SAS to be used **in conjunction with** Python and/or R rather than being used **instead of** Python and/or R. This is likely the case currently as some NSOs are working on converting their older SAS code to open source languages like R, hence may still operate SAS in alignment with newer open source scripts.[^tools-and-technology-10]

[^tools-and-technology-10]: Due to the complexity of the task, many NSOs are looking at LLMs to support the conversion of SAS code. For example see the use case of CSO Ireland (see [section 3.2 Large Language Models for Official Statistics: HLG-MOS 2023 White paper](https://unece.org/sites/default/files/2023-12/HLGMOS%20LLM%20Paper_Preprint_1.pdf)) or [INSEE (France)](https://my.visme.co/view/z4nodvzv-gpt-for-sas-to-r-slides-for-geneva#s1).

```{r}
#| echo: false

MONOLITH_LANG = sum(monolith_df$csharp == "Yes" | monolith_df$corcpp == "Yes" | monolith_df$java == "Yes" | monolith_df$vb == "Yes" | monolith_df$vba == "Yes")

MONOLITH_R_SAS = sum(monolith_df$r == "Yes" | monolith_df$sas == "Yes")

MODULAR_R_SAS = sum(modular_df$r == "Yes" | modular_df$sas == "Yes")
```

Third, there are some differences in programming languages used between NSOs with monolithic representative systems and NSOs with modular representative systems.

The most noteworthy observation is that Java, C#, C/C++, Visual Basic, and Visual Basic Applications (VBA) are somewhat commonly used by NSOs with monolithic representative systems (almost two thirds) and almost never used by NSOs with modular representative systems (less than one quarter).

Additionally, we notice that slightly over one third of NSOs with monolithic representative systems report using R or SAS, while almost two thirds of NSOs with modular representative systems report using R or SAS.

```{r}
#| echo: false
# Version control
dat <- data.frame(
  Frequency = c(
    monolith_df$python,
    monolith_df$r,
    monolith_df$java,
    monolith_df$csharp,
    monolith_df$corcpp,
    monolith_df$vb,
    monolith_df$vba,
    monolith_df$sas,
    monolith_df$sql
  ),
  Language = c(
    rep("Python", each=nrow(monolith_df)),
    rep("R", each=nrow(monolith_df)),
    rep("Java", each=nrow(monolith_df)),
    rep("C#", each=nrow(monolith_df)),
    rep("C/C++", each=nrow(monolith_df)),
    rep("Visual Basic", each=nrow(monolith_df)),
    rep("Visual Basic Applications", each=nrow(monolith_df)),
    rep("SAS", each=nrow(monolith_df)),
    rep("SQL", each=nrow(monolith_df))
  )
)

# Fill NA with zero
dat$Frequency = ifelse(dat$Frequency == "Yes", 1, 0)
ggplot(dat, aes(x=Language, y=Frequency)) + geom_bar(stat="identity", fill="#FFE873") + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + labs(title="[Monolith] Programming Languages Used")
```

```{r}
#| echo: false
# Version control
dat <- data.frame(
  Frequency = c(
    modular_df$python,
    modular_df$r,
    modular_df$vba,
    modular_df$sas,
    modular_df$sql,
    modular_df$none
  ),
  Language = c(
    rep("Python", each=nrow(modular_df)),
    rep("R", each=nrow(modular_df)),
    rep("Visual Basic Applications", each=nrow(modular_df)),
    rep("SAS", each=nrow(modular_df)),
    rep("SQL", each=nrow(modular_df)),
    rep("None", each=nrow(modular_df))
  )
)

# Fill NA with zero
dat$Frequency = ifelse(dat$Frequency == "Yes", 1, 0)
ggplot(dat, aes(x=Language, y=Frequency)) + geom_bar(stat="identity", fill="#FFE873") + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + labs(title="[Modular] Programming Languages Used")
```

## Data Storage Tools

We conclude the Tools and Technology portion of the survey by asking which data storage tools are in use by respondents in their CPI Production Systems.

```{r message = FALSE}
#| echo: false
#| warning: false
#| layout-ncol: 2
#| out-width: "100%"
#| fig-cap:
#| - Choice of Storage (Overall)
#| - Choice of Storage (Monolith)
#| - Choice of Storage (Hybrid)
#| - Choice of Storage (Modular)

library(dplyr)
library(ggplot2)

# df <- read.csv("./data/results.csv")
# df <- df[df[,2] != "",]

df <- df |> rename(
  obj_stor=colnames(df)[183],
  dbms=colnames(df)[184],
  olap_fmt=colnames(df)[185],
  fs=colnames(df)[186],
  other_ds=colnames(df)[187]
)

# Version control
dat <- data.frame(
  Frequency = c(
    df$obj_stor,
    df$dbms,
    df$olap_fmt,
    df$fs
  ),
  Storage = c(
    rep("Object Storage", each=nrow(df)),
    rep("DBMS", each=nrow(df)),
    rep("Analytics File Format", each=nrow(df)),
    rep("Filesystem", each=nrow(df))
  )
)

# Fill NA with zero
dat$Frequency = ifelse(dat$Frequency == "Yes", 1, 0)
ggplot(dat, aes(x=Storage, y=Frequency)) + geom_bar(stat="identity", fill="#FF9900") + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + labs(title="Storage Systems Used")

monolith_df <- monolith_df |> rename(
  obj_stor=colnames(monolith_df)[183],
  dbms=colnames(monolith_df)[184],
  olap_fmt=colnames(monolith_df)[185],
  fs=colnames(monolith_df)[186],
  other_ds=colnames(monolith_df)[187]
)

# Version control
dat <- data.frame(
  Frequency = c(
    monolith_df$dbms,
    monolith_df$fs
  ),
  Storage = c(
    rep("DBMS", each=nrow(monolith_df)),
    rep("Filesystem", each=nrow(monolith_df))
  )
)

# Fill NA with zero
dat$Frequency = ifelse(dat$Frequency == "Yes", 1, 0)
ggplot(dat, aes(x=Storage, y=Frequency)) + geom_bar(stat="identity", fill="#FF9900") + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + labs(title="[Monolith] Storage Systems Used")


hybrid_df <- hybrid_df |> rename(
  obj_stor=colnames(hybrid_df)[183],
  dbms=colnames(hybrid_df)[184],
  olap_fmt=colnames(hybrid_df)[185],
  fs=colnames(hybrid_df)[186],
  other_ds=colnames(hybrid_df)[187]
)

# Version control
dat <- data.frame(
  Frequency = c(
    hybrid_df$dbms,
    hybrid_df$fs
  ),
  Storage = c(
    rep("DBMS", each=nrow(hybrid_df)),
    rep("Filesystem", each=nrow(hybrid_df))
  )
)

# Fill NA with zero
dat$Frequency = ifelse(dat$Frequency == "Yes", 1, 0)
ggplot(dat, aes(x=Storage, y=Frequency)) + geom_bar(stat="identity", fill="#FF9900") + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + labs(title="[Hybrid] Storage Systems Used")



modular_df <- modular_df |> rename(
  obj_stor=colnames(modular_df)[183],
  dbms=colnames(modular_df)[184],
  olap_fmt=colnames(modular_df)[185],
  fs=colnames(modular_df)[186],
  other_ds=colnames(modular_df)[187]
)

# Version control
dat <- data.frame(
  Frequency = c(
    modular_df$dbms,
    modular_df$fs
  ),
  Storage = c(
    rep("DBMS", each=nrow(modular_df)),
    rep("Filesystem", each=nrow(modular_df))
  )
)

# Fill NA with zero
dat$Frequency = ifelse(dat$Frequency == "Yes", 1, 0)
ggplot(dat, aes(x=Storage, y=Frequency)) + geom_bar(stat="identity", fill="#FF9900") + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + labs(title="[Modular] Storage Systems Used")

```

We found that:

1.  A very small percentage of the respondents reported using analytics optimized file formats such as [Apache Parquet](https://parquet.apache.org/) in their CPI Production Systems. There is a small learning curve associated with using these file formats, but they offer many benefits such as columnar storage on disk, data types supported natively by the file format, and a significantly smaller storage footprint due to columnar data compression strategies[^tools-and-technology-11].

2.  There is an approximately equal split between the usage of Database Management Systems (DBMS) and file system storage, which is true across both NSOs with modular representative systems and NSOs with monolithic representative systems.

3.  The small number of respondents who reported using something in addition to DBMS or filesystem storage all belonged to NSOs with modular or hybrid representative systems.

[^tools-and-technology-11]: While there is a learning curve for some of the concepts involved, reading and writing to analytics-optimized file formats like Parquet is very easy due to the existence of many well-documented third party packages. For example, Python's Pandas can [read parquet files directly](https://pandas.pydata.org/docs/reference/api/pandas.read_parquet.html) as long as an engine like `pyarrow` or `fastparquet` is also installed.