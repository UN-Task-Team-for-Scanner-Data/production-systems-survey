# Introduction {#sec-intro}

::: {layout-ncol=2}

We created this survey about the state of Consumer Price Index (CPI) Production Systems on behalf of the [Task Team on Scanner Data](https://unstats.un.org/bigdata/task-teams/scanner/index.cshtml) under the [UN Committee of Experts on Big Data and Data Science for Official Statistics](https://unstats.un.org/bigdata/).

![](https://unstats.un.org/bigdata/assets/img/logo/logo_2021_long.png)
:::

While this report is specific to the state of CPI Production Systems at National Statistics Organizations (NSOs) around the world, we attempt to explain our results in a general way and highlight opportunities where our survey approach could be applied in related settings.

## Overview of CPI Production Systems

CPI Production Systems are complex [sociotechnical systems](https://en.wikipedia.org/wiki/Sociotechnical_system) that require significant expertise across multiple skill domains such as Economics, Statistics, and Computer Science in order to develop and maintain them. The recent adoption of alternative data sources[^1] has significantly increased the complexity of these systems, and has increased the importance of skills in newly emerging disciplines such as [Data Science](https://en.wikipedia.org/wiki/Data_science), [Data Engineering](https://en.wikipedia.org/wiki/Data_engineering), and [Analytics Engineering](https://www.getdbt.com/what-is-analytics-engineering).

[^1]: In the context of CPI systems, alternative data sources refer to data such as retailer scanner and web-scraped data that can be used to calculate the component price changes that are used in CPI calculations.

## What This Survey Is About

We are trying to characterize how CPI Systems and the teams that own them are organized in order to improve business outcomes for these teams.

Our survey asks a series of questions about how software systems and teams are organized with respect to a fairly generic data processing workflow. We then ask several questions related to the various tools and technologies being used by the various teams maintaining CPI Systems. We conclude by asking a series of questions related to business outcomes of interest.

## 	Why Did We Run This Survey? {#sec-why-run-this-survey}

In our experience, we've noticed that many teams who produce complicated analytics outputs struggle with managing system complexity.

While these teams are often comprised of individuals with strong analytical skills and significant domain knowledge, they often do not have training in software engineering. Therefore, they are often not exposed to the significant body of knowledge that has been developed over decades to deal with the kinds of system complexity problems that software developers are routinely exposed to.

Moreover, the nature of these complex analytical systems differ from traditional software systems in a number of important aspects[^3]:

| Complex Analytical Systems | Typical Software System |
| -------------------------- | ----------------------- |
| Multiple distinct scripts that are run sequentially and perform complex data manipulations. | One code base representing an entire application. |
| Running time measured in minutes/hours | Running time measured in milliseconds. |
| Human in the loop activities to interpret results. | Completely autonomous system. |
| Ad-hoc (messy) data gathered from whatever data sources are available. | Highly structured data whose schema is designed in lock step with the rest of the system. |
| Batch workloads that are run manually (or semi-manually). | System running continuously in an event loop waiting for user input. |
| Operate on a large fraction of an entire table quickly. | Search for one specific record in a large table quickly. |


Due to differences like those mentioned above, there is not a perfect mapping between best practices from the software engineering world and pain points currently experienced by teams maintaining Complex Analytical Systems. However, there are obviously some best practices from software engineering that are highly appropriate to solve some of problems faced by Complex Analytical Systems.

Therefore, our hope with this survey is to begin bridging the gap between well-understood industry best practices from the world of software engineering, and those aspects of Complex Analytical Systems that could benefit from these best practices.

More specifically, we are trying to understand the current state of Complex Analytical Systems and the teams who maintain them, using CPI Production Systems as a representative use case. Our hope is that the insights gained and the survey methodology may be valuable for other Complex Analytical Systems facing similar challenges.

[^3]: We are not implying that all "other" software systems have these characteristics. Rather, we are trying to draw contrast between aspects of Complex Analytical Systems that are most likely to be different from the kinds of systems a software engineer would typically develop and maintain.


## Related Work

We borrow and adapt several ideas presented in @skelton2019team such as the concepts of [Stream-aligned teams and the Flow of change](https://teamtopologies.com/key-concepts) in our survey. These concepts (discussed in greater detail in the following sections) can be applied to understand how teams are organized around the various steps in a complex data processing workflow.

We also borrow a number of ideas from @forsgren2018accelerate. Particularly, multiple of the DevOps Research and Assessment (DORA) metrics presented are highly relevant in measuring the business outcomes of teams that maintain CPI systems.[^2]

[^2]: We use slightly different terminology to refer to these concepts throughout the survey in order to use language that our target audience is most likely familiar with.

We believe that multiple ideas presented in @dehghani2022data are highly applicable to the CPI Systems under study. Specifically, we believe that the concept of [Data-as-a-Product](https://www.thoughtworks.com/en-ca/insights/articles/leveraging-data-as-a-product-a-strategic-imperative-for-business-leaders) (and teams organized around these Data Products) provides a useful framework for thinking about how these systems and teams interact with one another. We also contrast domain-oriented decentralized teams with centralized teams.

Although we do not make specific references to it in our survey, we believe the Reproducible Analytical Pipeline (RAP) work by @RAPsite does a good job at explaining how teams can introduce relevant tools and practices to workloads oriented around data processing.

Throughout this write up, we distinguish between software systems and IT professionals being **embedded in domain teams** versus being centralized **outside of domain teams**. Organizing software system architecture around business domains is not a new idea in software engineering (see Domain Driven Design by @evans2004domain, and more recently Software Architecture: The Hard Parts by @ford2021software and Fundamentals of Software Architecture by @richards2020fundamentals). However, we believe this distinction may not be well understood or formalized in the context of the Complex Analytical Systems described in @sec-why-run-this-survey, so we pay special attention to this distinction throughout this write up.

## How This Report Is Organized

@sec-concepts covers the key concepts used in the survey. @sec-sys-team analyzes our findings with respect to system and team organization.

## Note on Confidentiality and Privacy

As part of the administration of this survey, we ensured respondents that their data will be treated confidentiality. Therefore, no individual response data are made available in this report; all results presented are aggregated over all responses.
