---
title: CPI Production Systems
subtitle: Survey Analysis

author:
  - name: Collin Brown
    affiliation: Statistics Canada
  - name: Steve Martin
    affiliation: Statistics Canada
---

## Upfront Admin

::: {layout-ncol=2}
Survey created on behalf of the [Task Team on Scanner Data](https://unstats.un.org/bigdata/task-teams/scanner/index.cshtml) under the [UN Committee of Experts on Big Data and Data Science for Official Statistics](https://unstats.un.org/bigdata/).

Thank you for the helpful feedback and numerous contributions from our colleagues in the **Workstream on CPI Systems Architecture**
:::

![](https://unstats.un.org/bigdata/assets/img/logo/logo_2021_long.png)

**Note**: The full report can be found [here]().


## CPI Production Systems Background

- CPI Production Systems involve significant amounts of **code**, **documentation**, and **other non-code artifacts** (e.g., Excel Workbooks).

- These systems carry out complex business logic in order to **transform input data into output data**.

- These systems are often developed entirely or in large part by people **with domain expertise but without training in software engineering**.

## Why Run This Survey?

1. Many CPI Production Systems teams **struggle with managing system complexity**.

2. State of CPI Production Systems around the world is **unknown** (e.g., how are systems organized, how often are systems updated).

3. Provide **practical advice** based on the current state of systems.

## Related Work

A lot of related work is from the world of software engineering. **Notable Examples**:

- [Team Topologies](https://teamtopologies.com/) (@skelton2019team) looks at how to optimally organize teams.

- [Accelerate: The State of DevOps Report](https://cloud.google.com/devops/state-of-devops) (@forsgren2018accelerate) shares ideas around how to measure software delivery performance.

- [Data Mesh Architecture](https://www.datamesh-architecture.com/) (@dehghani2022data) introduces architecture concepts oriented around domain-aligned data product teams.

- [Reproducible Analytical Pipelines (RAP) Community of Practice](https://nhsdigital.github.io/rap-community-of-practice/) (@RAPsite) shares tools, principles, and techniques to create more robust analytical systems.

## Survey Concepts

- Goal is to characterize system layout, team organization, tool use, and system performance metrics.

- How to articulate important aspects of system architecture in a short survey?

<hr/>

> Need to introduce a simple conceptual model to communicate key system ideas.

## Survey Concepts - Systems

![](diagrams/gsbpm-systems.drawio.png){width=50% fig-align="center"}

We define a **system** as any indivisible (atomic) software component that takes **one or more data inputs** and produces **one or more data outputs**.

## Survey Concepts - Teams

A **team** is defined as a **group of individuals** who **maintain** one or more **systems**. 

| Team Type | Description |
| --------- | ----------- |
| Corporate IT | IT professionals **not in** the price statistics team. |
| Domain-Embedded IT | IT professionals **in** the price statistics team. |
| Domain-Embedded Analysts | non-IT professionals **in** the price statistics team. |
| Non-Domain Analysts | non-IT professionals **not in** the price statistics team.
| External Consultants or Contractors | Professionals outside of the organization to whom work is contracted. |

## Survey Concepts - Flow of Change

From left to right, we go from raw data to the production of the CPI.

![Flow of Change](./diagrams/gsbpm-systems-2.drawio.svg){#fig-flow-of-work width="90%"}

Flow of change based loosely on the General Statistical Business Process Model (GSBPM).

## Survey Concepts - Monolithic vs. Modular Architectures

::: {layout-ncol=2}
![Perfect Monolith Example](./diagrams/gsbpm-monolith.drawio.svg){#fig-monolith height="30%"}

![Perfect Modular Example](./diagrams/gsbpm-modular.drawio.svg){#fig-modular height="30%"}
:::

## Results - Which Steps are Systems Coupled Across?

![Conceptual diagram of loose and high coupling. Source: https://en.wikipedia.org/wiki/Coupling_(computer_programming)](https://upload.wikimedia.org/wikipedia/commons/thumb/0/09/CouplingVsCohesion.svg/330px-CouplingVsCohesion.svg.png){width="40%"}

**Question**: To what extent do distinct software modules depend on each other?

## Results - Which Steps are Systems Coupled Across?
```{r}
#| echo: false
#| warning: false
# -------------------
# Dataframe setup
# -------------------

library(dplyr)

# Load results
df <- read.csv("data/results.csv")  #[,67:116]
# Drop any incomplete responses
df <- df[df[,2] != "",]

# Helpers.
is_yes <- function(x) x == "Yes"

as_steps_matrix <- function(x, rows) {
  dn <- list(rows, c("Ingest", "Process", "Elementals", "Aggregate", "Finalize"))
  list(matrix(!is.na(x), ncol = 5, byrow = TRUE, dimnames = dn))
}

# Turn Q1 into a logical matrix.
crossings_Q1 <-df[df[,15] == "Yes",] |>
  rowwise() |>
  mutate(steps = as_steps_matrix(c_across(16:40), paste0("System ", 1:5)))

# Find 3 clusters.
clusters <- crossings_Q1 |>
  pull(steps) |>
  lapply(as.numeric) |>
  do.call(what = rbind) |>
  kmeans(3)


# How many times do we see **only** Ingestion and Processing, but not the other three?
ing_proc_crossings = 0
proc_elem_crossings = 0
elem_agg_crossings = 0
agg_fin_crossings = 0
ing_proc_elem_x = 0
proc_elem_agg_x = 0
elem_agg_fin_x = 0
first_4_x = 0
last_4_x = 0
all_5_x = 0
# Partition the Q3 matrices by cluster.
for (mat in crossings_Q1$steps) {
  for (ix in 1:5) {
    if (all(mat[ix,] == c(TRUE, TRUE, FALSE, FALSE, FALSE))) {
      ing_proc_crossings <- ing_proc_crossings + 1
    }
    if (all(mat[ix,] == c(FALSE, TRUE, TRUE, FALSE, FALSE))) {
      proc_elem_crossings <- proc_elem_crossings + 1
    }
    if (all(mat[ix,] == c(FALSE, FALSE, TRUE, TRUE, FALSE))) {
      elem_agg_crossings <- elem_agg_crossings + 1
    }
    if (all(mat[ix,] == c(FALSE, FALSE, FALSE, TRUE, TRUE))) {
      agg_fin_crossings <- agg_fin_crossings + 1
    }
    if (all(mat[ix,] == c(TRUE, TRUE, TRUE, FALSE, FALSE))) {
      ing_proc_elem_x <- ing_proc_elem_x + 1
    }
    if (all(mat[ix,] == c(FALSE, TRUE, TRUE, TRUE, FALSE))) {
      proc_elem_agg_x <- proc_elem_agg_x + 1
    }
    if (all(mat[ix,] == c(FALSE, FALSE, TRUE, TRUE, TRUE))) {
      elem_agg_fin_x <- elem_agg_fin_x + 1
    }
    if (all(mat[ix,] == c(TRUE, TRUE, TRUE, TRUE, FALSE))) {
      first_4_x <- first_4_x + 1
    }
    if (all(mat[ix,] == c(FALSE, TRUE, TRUE, TRUE, TRUE))) {
      last_4_x <- last_4_x + 1
    }
    if (all(mat[ix,] == c(TRUE, TRUE, TRUE, TRUE, TRUE))) {
      all_5_x <- all_5_x + 1
    }
  }
}
# split(crossings_Q1$steps, clusters$cluster)
```

| Data ingestion | Data processing | Elementary indexes | Aggregation | Finalization | Frequency |
| ----- | ----- | ---- | ----- | ----- | ---- |
| ✅ | ✅ | ❌ | ❌ | ❌ | `r ing_proc_crossings` |
| ✅ | ✅ | ✅ | ❌ | ❌ | `r ing_proc_elem_x` |
| ❌ | ✅ | ✅ | ✅ | ❌ | `r proc_elem_agg_x` |
| ✅ | ✅ | ✅ | ✅ | ✅ | `r all_5_x` |

## Results - Which Team Combinations are Common Within the Flow of Change?

```{r}
#| echo: false
#| warning: false

# Turn Q2 into a logical matrix.
crossings_Q2 <- df |>
  rowwise() |>
  mutate(steps = as_steps_matrix(
    c_across(42:66),
    c(
      "Corp. IT",
      "Domain IT",
      "Domain Analyst",
      "Other Analyst",
      "Consultant"
    )
  ))

# Find 3 clusters.
clusters <- crossings_Q2 |>
  pull(steps) |>
  lapply(as.numeric) |>
  do.call(what = rbind) |>
  kmeans(3)


# How many times do we see **only** Ingestion and Processing, but not the other three?
d_analyst_only = 0
stream_aligned = 0
cit_only = 0
dit_only = 0
it_only = 0
cit_d_analyst = 0
# Partition the Q3 matrices by cluster.
for (mat in crossings_Q2$steps) {
  for (ix in 1:5) {
    if (all(mat[,ix] == c(FALSE, FALSE, TRUE, FALSE, FALSE))) {
      d_analyst_only <- d_analyst_only + 1
    }
    if (all(mat[,ix] == c(FALSE, TRUE, TRUE, FALSE, FALSE))) {
      stream_aligned <- stream_aligned + 1
    }
    if (all(mat[,ix] == c(TRUE, FALSE, FALSE, FALSE, FALSE))) {
      cit_only <- cit_only + 1
    }
    if (all(mat[,ix] == c(FALSE, TRUE, FALSE, FALSE, FALSE))) {
      dit_only <- dit_only + 1
    }
    if (all(mat[,ix] == c(TRUE, TRUE, FALSE, FALSE, FALSE))) {
      it_only <- it_only + 1
    }
    if (all(mat[,ix] == c(TRUE, FALSE, TRUE, FALSE, FALSE))) {
      cit_d_analyst <- cit_d_analyst + 1
    }
  }
}
# split(crossings_Q1$steps, clusters$cluster)

```

| Corporate IT | Domain IT | Domain Analysts | Other Analysts | Consultants | Team Type | Frequency |
| ----- | ----- | ---- | ----- | ----- | ---- | ---- |
| ❌ | ❌ | ✅ | ❌ | ❌ | Domain Analysts | `r d_analyst_only` |
| ❌ | ✅ | ✅ | ❌ | ❌ | Domain Analysts & Domain IT | `r stream_aligned` |
| ✅ | ❌ | ✅ | ❌ | ❌ | Corp. IT & Domain Analysts | `r cit_d_analyst` |

## Results - Version Control System Use

:::: {.columns}

::: {.column width="50%"}
```{r, fig.width=10,fig.height=10}
#| echo: false
#| label: fig-comm-software
#| fig-cap: VCS used by survey respondents

library(dplyr)
library(ggplot2)

df <- read.csv("./data/results.csv")
df <- df[df[,2] != "",]

# Filter and rename columns used in the analysis for this page
df <- df |> rename(
  sg1_ing=colnames(df)[67],
  sg1_proc=colnames(df)[68],
  sg1_elem=colnames(df)[69],
  sg1_agg=colnames(df)[70],
  sg1_fin=colnames(df)[71],
  sg2_ing=colnames(df)[72],
  sg2_proc=colnames(df)[73],
  sg2_elem=colnames(df)[74],
  sg2_agg=colnames(df)[75],
  sg2_fin=colnames(df)[76],
  sg3_ing=colnames(df)[77],
  sg3_proc=colnames(df)[78],
  sg3_elem=colnames(df)[79],
  sg3_agg=colnames(df)[80],
  sg3_fin=colnames(df)[81],
  sg4_ing=colnames(df)[82],
  sg4_proc=colnames(df)[83],
  sg4_elem=colnames(df)[84],
  sg4_agg=colnames(df)[85],
  sg4_fin=colnames(df)[86],
  sg5_ing=colnames(df)[87],
  sg5_proc=colnames(df)[88],
  sg5_elem=colnames(df)[89],
  sg5_agg=colnames(df)[90],
  sg5_fin=colnames(df)[91],
  sg1_cit=colnames(df)[92],
  sg1_dit=colnames(df)[93],
  sg1_dan=colnames(df)[94],
  sg1_ean=colnames(df)[95],
  sg1_con=colnames(df)[96],
  sg2_cit=colnames(df)[97],
  sg2_dit=colnames(df)[98],
  sg2_dan=colnames(df)[99],
  sg2_ean=colnames(df)[100],
  sg2_con=colnames(df)[101],
  sg3_cit=colnames(df)[102],
  sg3_dit=colnames(df)[103],
  sg3_dan=colnames(df)[104],
  sg3_ean=colnames(df)[105],
  sg3_con=colnames(df)[106],
  sg4_cit=colnames(df)[107],
  sg4_dit=colnames(df)[108],
  sg4_dan=colnames(df)[109],
  sg4_ean=colnames(df)[110],
  sg4_con=colnames(df)[111],
  sg5_cit=colnames(df)[112],
  sg5_dit=colnames(df)[113],
  sg5_dan=colnames(df)[114],
  sg5_ean=colnames(df)[115],
  sg5_con=colnames(df)[116],
)
# df <- df[,67:116]

# Fill NA values with zero
# df[,67:116] <- 0

systems_matrix <- function(row) {
  q1 <- matrix(nrow=5, ncol=5)
  q1[1,] <- as.numeric(obs[,67:71])
  q1[2,] <- as.numeric(obs[,72:76])
  q1[3,] <- as.numeric(obs[,77:81])
  q1[4,] <- as.numeric(obs[,82:86])
  q1[5,] <- as.numeric(obs[,87:91])
  
  q1[is.na(q1)] = 0
  
  q1
}

maintainer_matrix <- function(row) {
  q2 <- matrix(nrow=5, ncol=5)
  q2[1,] <- as.numeric(obs[,92:96])
  q2[2,] <- as.numeric(obs[,97:101])
  q2[3,] <- as.numeric(obs[,102:106])
  q2[4,] <- as.numeric(obs[,107:111])
  q2[5,] <- as.numeric(obs[,112:116])
  
  q2[is.na(q2)] = 0
  
  q2
}

similarity_metric <- function(a, b) {
  num <- sum(a == TRUE & b == TRUE)
  denom <- sum(b == TRUE)
  num / denom
}

# ---------------------
# Add a column to indicate whether the organization has a monolith
# ---------------------

df$has_monolith = FALSE

for (i in 1:nrow(df)) {
  obs <- df[i,]
  # Get matrix of system groups and maintainers
  sys_grps <- systems_matrix(obs)
  maintainers <- maintainer_matrix(obs)
  # Define the monolith condition (i.e, there is only one system group that does
  # every GSBPM step).
  cit_idx <- all(as.logical(sys_grps[1,1:5])) |
             all(as.logical(sys_grps[2,1:5])) |
             all(as.logical(sys_grps[3,1:5])) |
             all(as.logical(sys_grps[4,1:5])) |
             all(as.logical(sys_grps[5,1:5])) 
  # If any system group is a monolith, add these counts to cumulative links and flag
  # this row as an organization that has at least one monolith.
  if (cit_idx & df[i, 15] != "No") {
    df[i, "has_monolith"] = TRUE
  }
}


# ---------------------
# Add a column to indicate whether the organization has a hybrid architecture
# ---------------------

df$has_hybrid_arch = FALSE

for (i in 1:nrow(df)) {
  obs <- df[i,]
  # Get matrix of system groups and maintainers
  sys_grps <- systems_matrix(obs)
  maintainers <- maintainer_matrix(obs)
  # Define the hybrid architecture condition (at least one GSBPM step defined in groups 1 and 2, all else zero)
  cit_idx <- (sys_grps[1,1] == 1 | sys_grps[1,2] == 1 | sys_grps[1,3] == 1 | sys_grps[1,4] == 1 | sys_grps[1,5] == 1) &
             (sys_grps[2,1] == 1 | sys_grps[2,2] == 1 | sys_grps[2,3] == 1 | sys_grps[2,4] == 1 | sys_grps[2,5] == 1) &
              all(sys_grps[3:5, 1:5] == 0)
  # If there are two system groups **and** these groups are not monoliths, then
  # we consider these to be hybrid systems. The rationale here is that if a representative
  # system has 2 system groups and each system group is a monolith, then this isn't really
  # a hybrid system with a "boundary" between two groups.
  if (cit_idx & !df[i, "has_monolith"]) {
    df[i, "has_hybrid_arch"] = TRUE
  }
}

# ---------------------
# Add a column to indicate whether the organization has a "modular" architecture
# ---------------------

df$has_modular = FALSE

for (i in 1:nrow(df)) {
  obs <- df[i,]
  # Get matrix of system groups and maintainers
  sys_grps <- systems_matrix(obs)
  maintainers <- maintainer_matrix(obs)
  # Define the modular architecture
  cit_idx <- (sys_grps[1,1] == 1 | sys_grps[1,2] == 1 | sys_grps[1,3] == 1 | sys_grps[1,4] == 1 | sys_grps[1,5] == 1) &
             (sys_grps[2,1] == 1 | sys_grps[2,2] == 1 | sys_grps[2,3] == 1 | sys_grps[2,4] == 1 | sys_grps[2,5] == 1) &
             (sys_grps[2,1] == 1 | sys_grps[2,2] == 1 | sys_grps[2,3] == 1 | sys_grps[2,4] == 1 | sys_grps[2,5] == 1)
  if (cit_idx & !df[i, "has_monolith"] & !df[i, "has_hybrid_arch"]) {
    df[i, "has_modular"] = TRUE
  }
}

# Any organization that doesn't fit one of the 3 definitions above is excluded
# because the answers are incomplete. Drop these records from the analysis
df <- df[df$has_monolith | df$has_hybrid_arch | df$has_modular, ]

# ---------------------
# Add a column to indicate whether the organization has stream aligned teams
# maintaining the representative system
# ---------------------

df$has_stream_aligned_team = FALSE

# This is the order of the maintainer columns
# c("Corporate IT", "Domain-Embedded IT", "Domain-Embedded Analysts", "Elsewhere Analysts", "Consultants")

for (i in 1:nrow(df)) {
  obs <- df[i,]
  # Get matrix of system groups and maintainers
  sys_grps <- systems_matrix(obs)
  maintainers <- maintainer_matrix(obs)
  # Define the stream aligned team condition as one or more maintainer groups being comprised of either
  # domain-analysts only, domain-IT only, or both domain analysts and domain IT (but no other groups).
  idx <- (maintainers[1,1] == 0 & maintainers[1,4] == 0 & maintainers[1,5] == 0) & (maintainers[1,2] == 1 | maintainers[1,3] == 1) |
         (maintainers[2,1] == 0 & maintainers[2,4] == 0 & maintainers[2,5] == 0) & (maintainers[2,2] == 1 | maintainers[2,3] == 1) |
         (maintainers[3,1] == 0 & maintainers[3,4] == 0 & maintainers[3,5] == 0) & (maintainers[3,2] == 1 | maintainers[3,3] == 1) |
         (maintainers[4,1] == 0 & maintainers[4,4] == 0 & maintainers[4,5] == 0) & (maintainers[4,2] == 1 | maintainers[4,3] == 1) |
         (maintainers[5,1] == 0 & maintainers[5,4] == 0 & maintainers[5,5] == 0) & (maintainers[5,2] == 1 | maintainers[5,3] == 1)
  if (idx) {
    df[i, "has_stream_aligned_team"] = TRUE
  }
}

# ---------------------
# Add a column to indicate whether the organization has IT-only teams maintaining
# any of its representative systems
# ---------------------

df$has_it_only_team = FALSE

# This is the order of the maintainer columns
# c("Corporate IT", "Domain-Embedded IT", "Domain-Embedded Analysts", "Elsewhere Analysts", "Consultants")

for (i in 1:nrow(df)) {
  obs <- df[i,]
  # Get matrix of system groups and maintainers
  sys_grps <- systems_matrix(obs)
  maintainers <- maintainer_matrix(obs)
  # Define the stream aligned team condition as one or more maintainer groups being comprised of either
  # domain-analysts only, domain-IT only, or both domain analysts and domain IT (but no other groups).
  idx <- (maintainers[1,3] == 0 & maintainers[1,4] == 0 & maintainers[1,5] == 0) & (maintainers[1,2] == 1 | maintainers[1,1] == 1) |
         (maintainers[2,3] == 0 & maintainers[2,4] == 0 & maintainers[2,5] == 0) & (maintainers[2,2] == 1 | maintainers[2,1] == 1) |
         (maintainers[3,3] == 0 & maintainers[3,4] == 0 & maintainers[3,5] == 0) & (maintainers[3,2] == 1 | maintainers[3,1] == 1) |
         (maintainers[4,3] == 0 & maintainers[4,4] == 0 & maintainers[4,5] == 0) & (maintainers[4,2] == 1 | maintainers[4,1] == 1) |
         (maintainers[5,3] == 0 & maintainers[5,4] == 0 & maintainers[5,5] == 0) & (maintainers[5,2] == 1 | maintainers[5,1] == 1)
  if (idx) {
    df[i, "has_it_only_team"] = TRUE
  }
}

# ---------------------
# Add a column to indicate whether the organization has analyst-only teams maintaining
# any of its representative systems
# ---------------------

df$has_analyst_only_team = FALSE

# This is the order of the maintainer columns
# c("Corporate IT", "Domain-Embedded IT", "Domain-Embedded Analysts", "Elsewhere Analysts", "Consultants")

for (i in 1:nrow(df)) {
  obs <- df[i,]
  # Get matrix of system groups and maintainers
  sys_grps <- systems_matrix(obs)
  maintainers <- maintainer_matrix(obs)
  # Define the stream aligned team condition as one or more maintainer groups being comprised of either
  # domain-analysts only, domain-IT only, or both domain analysts and domain IT (but no other groups).
  idx <- (maintainers[1,1] == 0 & maintainers[1,2] == 0 & maintainers[1,5] == 0) & (maintainers[1,3] == 1 | maintainers[1,4] == 1) |
         (maintainers[2,1] == 0 & maintainers[2,2] == 0 & maintainers[2,5] == 0) & (maintainers[2,3] == 1 | maintainers[2,4] == 1) |
         (maintainers[3,1] == 0 & maintainers[3,2] == 0 & maintainers[3,5] == 0) & (maintainers[3,3] == 1 | maintainers[3,4] == 1) |
         (maintainers[4,1] == 0 & maintainers[4,2] == 0 & maintainers[4,5] == 0) & (maintainers[4,3] == 1 | maintainers[4,4] == 1) |
         (maintainers[5,1] == 0 & maintainers[5,2] == 0 & maintainers[5,5] == 0) & (maintainers[5,3] == 1 | maintainers[5,4] == 1)
  if (idx) {
    df[i, "has_analyst_only_team"] = TRUE
  }
}

# ---------------------
# Add a column to indicate whether the organization has "other" teams maintaining
# any of its representative systems
# ---------------------

df$has_other_mix_team = FALSE

# This is the order of the maintainer columns
# c("Corporate IT", "Domain-Embedded IT", "Domain-Embedded Analysts", "Elsewhere Analysts", "Consultants")

for (i in 1:nrow(df)) {
  obs <- df[i,]
  # Get matrix of system groups and maintainers
  sys_grps <- systems_matrix(obs)
  maintainers <- maintainer_matrix(obs)
  # An "Other" mix is anything that's not stream aligned, IT-only, or analyst-only.
  # Any organization that doesn't have any of the other team types is "other".
  if (!df[i, "has_stream_aligned_team"] & !df[i, "has_it_only_team"] & !df[i, "has_analyst_only_team"]) {
    df[i, "has_other_mix_team"] = TRUE
  }
}

team_arch_mat <- matrix(nrow=5, ncol=3)

# mono-stream
team_arch_mat[1,1] <- similarity_metric(df$has_monolith, df$has_stream_aligned_team)
# mono-it-only
team_arch_mat[2,1] <- similarity_metric(df$has_monolith, df$has_it_only_team)
# mono-analyst-only
team_arch_mat[3,1] <- similarity_metric(df$has_monolith, df$has_analyst_only_team)
# Other mix teams
team_arch_mat[4,1] <- similarity_metric(df$has_monolith, df$has_other_mix_team)
# Sample average (i.e., all teams)
team_arch_mat[5,1] <- similarity_metric(df$has_monolith, rep(TRUE, nrow(df)))

# hybrid-stream
team_arch_mat[1,2] <- similarity_metric(df$has_hybrid_arch, df$has_stream_aligned_team)
# hybrid-it-only
team_arch_mat[2,2] <- similarity_metric(df$has_hybrid_arch, df$has_it_only_team)
# hybrid-analyst-only
team_arch_mat[3,2] <- similarity_metric(df$has_hybrid_arch, df$has_analyst_only_team)
# Other mix teams
team_arch_mat[4,2] <- similarity_metric(df$has_hybrid_arch, df$has_other_mix_team)
# Sample average (i.e., all teams)
team_arch_mat[5,2] <- similarity_metric(df$has_hybrid_arch, rep(TRUE, nrow(df)))

# modular-stream
team_arch_mat[1,3] <- similarity_metric(df$has_modular, df$has_stream_aligned_team)
# modular-it-only
team_arch_mat[2,3] <- similarity_metric(df$has_modular, df$has_it_only_team)
# modular-analyst-only
team_arch_mat[3,3] <- similarity_metric(df$has_modular, df$has_analyst_only_team)
# Other mix teams
team_arch_mat[4,3] <- similarity_metric(df$has_modular, df$has_other_mix_team)
# Sample average (i.e., all teams)
team_arch_mat[5,3] <- similarity_metric(df$has_modular, rep(TRUE, nrow(df)))


rownames(team_arch_mat) <- c("Stream Aligned Team", "IT-Only Team", "Analyst-Only Team", "Other Mix", "Sample Average")
colnames(team_arch_mat) <- c("Monolith", "Hybrid", "Modular")

# Define separate dfs for each architecture type and team type
monolith_df = df[df$has_monolith,]
hybrid_df = df[df$has_hybrid_arch,]
modular_df = df[df$has_modular,]

stream_aligned_df = df[df$has_stream_aligned_team,]
it_only_df = df[df$has_it_only_team,]
analyst_only_df = df[df$has_analyst_only_team,]
other_mix_df = df[df$has_other_mix_team,]

df <- df |> rename(
  use_open_source_pkg=colnames(df)[118],
  not_use_not_know=colnames(df)[120],
  not_use_insuff_doc=colnames(df)[121],
  not_use_code_not_maintain=colnames(df)[122],
  not_use_not_suitable=colnames(df)[123],
  not_use_not_integrate=colnames(df)[124],
  not_use_no_skills=colnames(df)[125],
  not_use_other=colnames(df)[126],
  vc_git=colnames(df)[137],
  vc_github=colnames(df)[138],
  vc_svn=colnames(df)[139],
  vc_hg=colnames(df)[140],
  vc_commercial=colnames(df)[141],
  vc_naming_convention=colnames(df)[142],
  vc_none=colnames(df)[143],
  vc_other=colnames(df)[144],
  pm_jira=colnames(df)[145],
  pm_gh_proj=colnames(df)[146],
  pm_gitlab_issue=colnames(df)[147],
  pm_share_excel=colnames(df)[148],
  pm_none=colnames(df)[149],
  pm_other=colnames(df)[150],
  cs_warehouse=colnames(df)[173],
  cs_sas=colnames(df)[174],
  cs_stata=colnames(df)[175],
  cs_matlab=colnames(df)[176],
  cs_spss=colnames(df)[177],
  cs_excel=colnames(df)[178],
  cs_pbi=colnames(df)[179],
  cs_access=colnames(df)[180],
  cs_none=colnames(df)[181],
  cs_other=colnames(df)[182]
)

# Version control
dat <- data.frame(
  Frequency = c(df$vc_git, df$vc_github, df$vc_commercial, df$vc_naming_convention, df$vc_none),
  VCS = c(
    rep("Git", each=nrow(df)),
    rep("GitHub/GitLab", each=nrow(df)),
    rep("Built-In Versioning", each=nrow(df)),
    rep("File Naming Conventions", each=nrow(df)),
    rep("None", each=nrow(df))
  )
)

# Fill NA with zero
dat$Frequency = ifelse(dat$Frequency == "Yes", 1, 0)
ggplot(dat, aes(x=VCS, y=Frequency)) + geom_bar(stat="identity", fill="#F1502F") + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + labs(title="Version Control Systems Used")

NUM_NONE_OR_FILE_NAMING_CONVENTION = sum(df$vc_none == "Yes" | df$vc_naming_convention == "Yes")

GIT_OR_GITHUB = sum(df$vc_git == "Yes" | df$vc_github == "Yes")
```
:::

::: {.column width="50%"}
- `r NUM_NONE_OR_FILE_NAMING_CONVENTION` respondents reported **not using a VCS at all**, or using file-naming conventions only. E.g.,

    - `analysis_v5_final_2025_03.py`
    
    - `analysis_v6_FINAL_2025_03_edits.py`

- `r GIT_OR_GITHUB` respondents reported using some combination of GitHub/GitLab, or just using Git locally.
:::

::::

## Results - Commercial Software Use

:::: {.columns}
::: {.column width="50%"}
```{r, fig.width=10,fig.height=10}
#| echo: false
#| label: fig-vcs
#| fig-cap: VCS used by survey respondents


# Version control
dat <- data.frame(
  Frequency = c(df$cs_warehouse, df$cs_sas, df$cs_excel, df$cs_pbi, df$cs_access, df$cs_none),
  Software = c(
    rep("Data Warehouse", each=nrow(df)),
    rep("SPSS", each=nrow(df)),
    rep("Excel", each=nrow(df)),
    rep("Power BI", each=nrow(df)),
    rep("MS Access", each=nrow(df)),
    rep("None", each=nrow(df))
  )
)

# Fill NA with zero
dat$Frequency = ifelse(dat$Frequency == "Yes", 1, 0)
ggplot(dat, aes(x=Software, y=Frequency)) + geom_bar(stat="identity", fill="#1d6f42") + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + labs(title="Commercial Software Used")
```
:::
::: {.column width="50%"}
- Over 2/3 of the respondents listed that Microsoft Excel was used in their CPI Production Systems.

- Excel is useful for beginner-friendly tabular data analysis, however, not an ideal tool for expressing complex business logic.

- Excel Workbooks encourage a high degree of coupling between business logic and data.
:::
::::

## Results - Project Management Software Use

:::: {.columns}

::: {.column width="50%"}
```{r, fig.width=10,fig.height=10}
#| echo: false

# Project Management
dat <- data.frame(
  Frequency = c(df$pm_jira, df$pm_gitlab_issue, df$pm_share_excel, df$pm_none),
  Software = c(
    rep("Jira", each=nrow(df)),
    rep("GitLab Milestones", each=nrow(df)),
    rep("Shared Excel Workbook", each=nrow(df)),
    rep("None", each=nrow(df))
  )
)

# Fill NA with zero
dat$Frequency = ifelse(dat$Frequency == "Yes", 1, 0)
ggplot(dat, aes(x=Software, y=Frequency)) + geom_bar(stat="identity", fill="#0052CC") + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + labs(title="Project Management Software Used")
```
:::

::: {.column width="50%"}

```{r}
#| echo: false

NUM_EXCEL_WB = sum(df$pm_share_excel == "Yes")
NUM_NONE = sum(df$pm_none == "Yes")
NUM_SOMETHING_ELSE = sum(df$pm_gh_proj == "Yes" | df$pm_gitlab_issue == "Yes" | df$pm_jira == "Yes" | df$pm_other == "Yes")
```
- `r NUM_EXCEL_WB` respondents report using a shared Excel workbook for project management.

- `r NUM_NONE` report using no software for project management.

- `r NUM_SOMETHING_ELSE` report using some other software for project management, such as Jira, GitLab, or GitHub. 
:::
::::


## Results - Programming Language Use

:::: {.columns}

::: {.column width="50%"}
```{r, fig.width=10,fig.height=10}
#| echo: false

library(dplyr)
library(ggplot2)

# df <- read.csv("./data/results.csv")
# df <- df[df[,2] != "",]

df <- df |> rename(
  python=colnames(df)[151],
  r=colnames(df)[152],
  julia=colnames(df)[153],
  scala=colnames(df)[154],
  java=colnames(df)[155],
  csharp=colnames(df)[156],
  corcpp=colnames(df)[157],
  vb=colnames(df)[158],
  vba=colnames(df)[159],
  sas=colnames(df)[160],
  stata=colnames(df)[161],
  spss=colnames(df)[162],
  sql=colnames(df)[163],
  none=colnames(df)[164],
  other=colnames(df)[165]
)

modular_df <- modular_df |> rename(
  python=colnames(modular_df)[151],
  r=colnames(modular_df)[152],
  julia=colnames(modular_df)[153],
  scala=colnames(modular_df)[154],
  java=colnames(modular_df)[155],
  csharp=colnames(modular_df)[156],
  corcpp=colnames(modular_df)[157],
  vb=colnames(modular_df)[158],
  vba=colnames(modular_df)[159],
  sas=colnames(modular_df)[160],
  stata=colnames(modular_df)[161],
  spss=colnames(modular_df)[162],
  sql=colnames(modular_df)[163],
  none=colnames(modular_df)[164],
  other=colnames(modular_df)[165]
)

monolith_df <- monolith_df |> rename(
  python=colnames(monolith_df)[151],
  r=colnames(monolith_df)[152],
  julia=colnames(monolith_df)[153],
  scala=colnames(monolith_df)[154],
  java=colnames(monolith_df)[155],
  csharp=colnames(monolith_df)[156],
  corcpp=colnames(monolith_df)[157],
  vb=colnames(monolith_df)[158],
  vba=colnames(monolith_df)[159],
  sas=colnames(monolith_df)[160],
  stata=colnames(monolith_df)[161],
  spss=colnames(monolith_df)[162],
  sql=colnames(monolith_df)[163],
  none=colnames(monolith_df)[164],
  other=colnames(monolith_df)[165]
)

# Version control
dat <- data.frame(
  Frequency = c(
    df$python,
    df$r,
    df$java,
    df$csharp,
    df$corcpp,
    df$vb,
    df$vba,
    df$sas,
    df$sql,
    df$none
  ),
  Language = c(
    rep("Python", each=nrow(df)),
    rep("R", each=nrow(df)),
    rep("Java", each=nrow(df)),
    rep("C#", each=nrow(df)),
    rep("C/C++", each=nrow(df)),
    rep("Visual Basic", each=nrow(df)),
    rep("Visual Basic Applications", each=nrow(df)),
    rep("SAS", each=nrow(df)),
    rep("SQL", each=nrow(df)),
    rep("None", each=nrow(df))
  )
)

# Fill NA with zero
dat$Frequency = ifelse(dat$Frequency == "Yes", 1, 0)
ggplot(dat, aes(x=Language, y=Frequency)) + geom_bar(stat="identity", fill="#FFE873") + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + labs(title="Programming Languages Used")

NUM_SQL = sum(df$sql == "Yes")

PYTHON_OR_R_OR_SAS = sum(df$python == "Yes" | df$r == "Yes" | df$sas == "Yes")
PYTHON_OR_R_NOT_SAS = sum((df$python == "Yes" | df$r == "Yes") & df$sas == "No")

NONE_LANGUAGE = sum(df$none == "Yes")
```
:::

::: {.column width="50%"}
- `r NUM_SQL` respondents reported using SQL in their CPI Production Systems.

- `r PYTHON_OR_R_OR_SAS` reported using Python or R or SAS.

- `r PYTHON_OR_R_NOT_SAS` reported using Python or R, but **not** SAS.

- `r NONE_LANGUAGE` reported using no programming language.
:::

::::

## Results - Programming Language Use (Monolith vs. Modular)

:::: {.columns}

::: {.column width="50%"}
```{r, fig.width=10,fig.height=10}
#| echo: false
# Version control
dat <- data.frame(
  Frequency = c(
    monolith_df$python,
    monolith_df$r,
    monolith_df$java,
    monolith_df$csharp,
    monolith_df$corcpp,
    monolith_df$vb,
    monolith_df$vba,
    monolith_df$sas,
    monolith_df$sql
  ),
  Language = c(
    rep("Python", each=nrow(monolith_df)),
    rep("R", each=nrow(monolith_df)),
    rep("Java", each=nrow(monolith_df)),
    rep("C#", each=nrow(monolith_df)),
    rep("C/C++", each=nrow(monolith_df)),
    rep("Visual Basic", each=nrow(monolith_df)),
    rep("Visual Basic Applications", each=nrow(monolith_df)),
    rep("SAS", each=nrow(monolith_df)),
    rep("SQL", each=nrow(monolith_df))
  )
)

# Fill NA with zero
dat$Frequency = ifelse(dat$Frequency == "Yes", 1, 0)
ggplot(dat, aes(x=Language, y=Frequency)) + geom_bar(stat="identity", fill="#FFE873") + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + labs(title="[Monolith] Programming Languages Used")
```
:::

::: {.column width="50%"}
```{r, fig.width=10,fig.height=10}
#| echo: false
# Version control
dat <- data.frame(
  Frequency = c(
    modular_df$python,
    modular_df$r,
    modular_df$vba,
    modular_df$sas,
    modular_df$sql,
    modular_df$none
  ),
  Language = c(
    rep("Python", each=nrow(modular_df)),
    rep("R", each=nrow(modular_df)),
    rep("Visual Basic Applications", each=nrow(modular_df)),
    rep("SAS", each=nrow(modular_df)),
    rep("SQL", each=nrow(modular_df)),
    rep("None", each=nrow(modular_df))
  )
)

# Fill NA with zero
dat$Frequency = ifelse(dat$Frequency == "Yes", 1, 0)
ggplot(dat, aes(x=Language, y=Frequency)) + geom_bar(stat="identity", fill="#FFE873") + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + labs(title="[Modular] Programming Languages Used")
```
:::

::::

## Results - Storage Use

TODO: insert chart

## Results - System Age

TODO: insert figures

- Monolithic architectures most likely to have systems between 6-10 years or 11-20 years old.

- IT-Only teams less likely to have systems older than 20 years compared to Stream Aligned teams.

- By far most common answer for Other Mix teams is system age between 6-10 years.

## Results - Update Frequency

TODO: insert figures

- Non-trivial fraction of respondents never update the majority of systems 

- Monolithic systems more likely to never update than modular systems.

- IT-Only teams more likely to update systems frequently than other team types.

- Other Mix teams most likely to never update or update very infrequently.

- **All team types** reported multiple "never update" answers.

## Results - Number of Individuals

- Most NSOs require 2-3 individuals or 4-6 individuals to complete **small changes** and **large changes** to systems.

## Results - Lead Time

[Lead time](https://en.wikipedia.org/wiki/Lead_time): the amount of time required to get an end-to-end change to a CPI Production System implemented.

- Most NSOs reported lead time of "within 1 day" or "within 1 week" for **small changes** (a non-trivial fraction reported "within 1 month").

- Monolithic systems more likely to report "within 1 year" or "more than 1 year" for **large changes** compared to modular systems.

- Modular systems never reported "can't be modified" or "too complex" for the **large changes** lead time question.

- Stream-aligned teams and analyst-only teams were most likely to report "within 1 month" for **large changes** compared to any other answer.

## Results - Alternative Data Usage

- Almost 2/3 of respondents don't use Alternative Data Sources (ADS) at all.

- Of those who use ADS, their CPIs are comprised of "less than 10%" or "between 10% and 30%" alternative data by expenditure weight.

- Of those respondents who do not use ADS, most of them would like "between 10% and 30%" or "between 30% and 50%" of their CPI to be comprised of alternative data by expenditure weight.

## Results - Alternative Data Challenges

In the following order, the most commonly cited ADS challenges are:

1. Lack of data provider cooperation

2. Insufficient capacity

3. Insufficient technical skills to make use of ADS

4. Lack of methodology knowledge to make use of ADS

5. Appropriate data are not available

## Results - System Development Challenges (In General)

In the following order, the most commonly cited challenges are:

1. Lack of staff

2. Insufficient technical skills

3. Managing complexity of system interactions (e.g., passing data between systems)

4. Managing complexity of the system itself (e.g., managing a complex codebase)

5. Verifying the correct behaviour of a system

## Practical Suggestions

- Think explicitly about system boundaries.

- Think explicitly about data interchange between systems.

- Embed technical expertise in business domain teams.

- Version control all the things.

- Practice updating systems more frequently.

## Future Work

Two main follow-questions from our survey.

1. Effectively managing the complexity of CPI Production Systems **in practice** is far from a solved problem, despite viable solutions existing for all of the component problems. **How can this gap be bridged**?

2. Are lessons about system architecture and team organization from software engineering applicable to complex analytical systems like the CPI Production Systems studied in this survey?

## References {.unnumbered}

::: {#refs}
:::
